{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "085106db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "CSV_PATH = os.path.join(os.getcwd(), 'results_2.2.csv')\n",
    "PLOTS_DIR = os.path.join(os.getcwd(), 'plots')\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "res = pd.read_csv(CSV_PATH)\n",
    "if 'user' not in res.columns:\n",
    "    res['user'] = 'unknown'\n",
    "\n",
    "res['n'] = res['n'].astype(int)\n",
    "res['sparsity'] = res['sparsity'].astype(int)\n",
    "res['reps'] = res['reps'].astype(int)\n",
    "res['threads_label'] = res['threads'].astype(str)\n",
    "\n",
    "def threads_to_int(x):\n",
    "    if str(x).lower() == 'sequential':\n",
    "        return -1\n",
    "    try:\n",
    "        return int(x)\n",
    "    except Exception:\n",
    "        return 1\n",
    "\n",
    "res['threads'] = res['threads_label'].apply(threads_to_int)\n",
    "\n",
    "# Component labels for timing breakdown (only components available in CSV)\n",
    "component_labels = {\n",
    "    'time_init': 'Init',\n",
    "    'time_csr_construct': 'CSR Construct',\n",
    "    'time_spmv_total': 'CSR SpMV',\n",
    "    'time_dense_total': 'Dense'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f38d91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timing breakdown multiplot (similar to plotter_2_1)\n",
    "def plot_timing_breakdown_multiplots(df, user):\n",
    "    user_data = df[df['user'] == user].copy()\n",
    "    if user_data.empty:\n",
    "        return\n",
    "    \n",
    "    # Get unique (n, sparsity) combinations\n",
    "    configs = user_data.groupby(['n', 'sparsity']).size().reset_index()[['n', 'sparsity']]\n",
    "    configs = configs.sort_values(['n', 'sparsity']).reset_index(drop=True)\n",
    "    \n",
    "    if len(configs) == 0:\n",
    "        return\n",
    "    \n",
    "    # Create subplots (2x2 grid)\n",
    "    nplots = min(len(configs), 4)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx in range(nplots):\n",
    "        n = configs.iloc[idx]['n']\n",
    "        sparsity = configs.iloc[idx]['sparsity']\n",
    "        \n",
    "        config_data = user_data[(user_data['n'] == n) & (user_data['sparsity'] == sparsity)].copy()\n",
    "        \n",
    "        # Compute mean and std across runs per threads\n",
    "        mean_data = config_data.groupby('threads').mean(numeric_only=True).reset_index()\n",
    "        std_data = config_data.groupby('threads').std(numeric_only=True).reset_index().fillna(0)\n",
    "        \n",
    "        mean_data = mean_data.sort_values('threads').reset_index(drop=True)\n",
    "        std_data = std_data.set_index('threads').reindex(mean_data['threads']).reset_index(drop=True)\n",
    "        \n",
    "        ax = axes[idx]\n",
    "        x_positions = np.arange(len(mean_data))\n",
    "        \n",
    "        bottom = np.zeros(len(mean_data))\n",
    "        available_components = [c for c in component_labels if c in mean_data.columns]\n",
    "        \n",
    "        for component in available_components:\n",
    "            values = mean_data[component].values\n",
    "            errs = std_data[component].values if component in std_data.columns else np.zeros_like(values)\n",
    "            # Clamp error bars to not go below zero\n",
    "            errs = np.minimum(errs, values)\n",
    "            label = component_labels[component] if np.max(values) > 1e-6 else None\n",
    "            ax.bar(x_positions, values, bottom=bottom, yerr=errs, capsize=3, \n",
    "                   label=label, alpha=0.85, width=0.6)\n",
    "            bottom += values\n",
    "        \n",
    "        ax.set_xlabel('Number of Threads')\n",
    "        ax.set_ylabel('Time (seconds)')\n",
    "        ax.set_title(f'n={int(n)}, sparsity={int(sparsity)}%')\n",
    "        ax.set_xticks(x_positions)\n",
    "        tick_labels = mean_data['threads'].apply(lambda x: 'sequential' if int(x) == -1 else str(int(x)))\n",
    "        ax.set_xticklabels(tick_labels)\n",
    "        if idx == 0:\n",
    "            ax.legend(fontsize=8)\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(nplots, 4):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    fig.suptitle(f'Execution Time Breakdown (User: {user})', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fname = os.path.join(PLOTS_DIR, f'timing_breakdown_all_configs_{user}.png')\n",
    "    fig.savefig(fname, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# Compact timing plots - now combined into subplots\n",
    "def plot_compact_timing_subplots(df, user):\n",
    "    user_data = df[df['user'] == user].copy()\n",
    "    if user_data.empty:\n",
    "        return\n",
    "    \n",
    "    # Get unique (n, sparsity) combinations\n",
    "    configs = user_data.groupby(['n', 'sparsity']).size().reset_index()[['n', 'sparsity']]\n",
    "    configs = configs.sort_values(['n', 'sparsity']).reset_index(drop=True)\n",
    "    \n",
    "    if len(configs) == 0:\n",
    "        return\n",
    "    \n",
    "    # Create subplots (2x2 grid)\n",
    "    nplots = min(len(configs), 4)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx in range(nplots):\n",
    "        n = configs.iloc[idx]['n']\n",
    "        sparsity = configs.iloc[idx]['sparsity']\n",
    "        \n",
    "        data = user_data[(user_data['n'] == n) & (user_data['sparsity'] == sparsity)].copy()\n",
    "        if data.empty:\n",
    "            continue\n",
    "            \n",
    "        summary_mean = data.groupby('threads').mean(numeric_only=True).reset_index()\n",
    "        summary_std = data.groupby('threads').std(numeric_only=True).reset_index().fillna(0)\n",
    "        summary_mean = summary_mean.sort_values('threads')\n",
    "        summary_std = summary_std.set_index('threads').reindex(summary_mean['threads']).reset_index(drop=True)\n",
    "\n",
    "        threads = summary_mean['threads'].values\n",
    "        width = 0.25\n",
    "        x = np.arange(len(threads))\n",
    "\n",
    "        ax = axes[idx]\n",
    "        # Clamp error bars for each component\n",
    "        err_csr = np.minimum(summary_std['time_csr_construct'].values, \n",
    "                             summary_mean['time_csr_construct'].values)\n",
    "        err_spmv = np.minimum(summary_std['time_spmv_total'].values, \n",
    "                              summary_mean['time_spmv_total'].values)\n",
    "        err_dense = np.minimum(summary_std['time_dense_total'].values, \n",
    "                               summary_mean['time_dense_total'].values)\n",
    "        \n",
    "        ax.bar(x - width, summary_mean['time_csr_construct'].values, width, \n",
    "               yerr=err_csr, capsize=3, \n",
    "               label='CSR construct', color='#4C72B0')\n",
    "        ax.bar(x, summary_mean['time_spmv_total'].values, width, \n",
    "               yerr=err_spmv, capsize=3, \n",
    "               label='CSR SpMV', color='#55A868')\n",
    "        ax.bar(x + width, summary_mean['time_dense_total'].values, width, \n",
    "               yerr=err_dense, capsize=3, \n",
    "               label='Dense', color='#C44E52')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels([str(int(t)) if t != -1 else 'seq' for t in threads])\n",
    "        ax.set_xlabel('Threads')\n",
    "        ax.set_ylabel('Time (s)')\n",
    "        ax.set_title(f'n={n} s={sparsity}%')\n",
    "        ax.grid(axis='y', alpha=0.25)\n",
    "        if idx == 0:\n",
    "            ax.legend(fontsize=8)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(nplots, 4):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    fig.suptitle(f'Component-wise Time Comparison (User: {user})', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fname = os.path.join(PLOTS_DIR, f'compact_timing_all_{user}.png')\n",
    "    fig.savefig(fname, dpi=300)\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aac48035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSR parallel speedup (baseline = sequential CSR) with same formatting as previous speedup plots\n",
    "def plot_csr_parallel_speedup_subplots(df, user):\n",
    "    user_data = df[df['user'] == user].copy()\n",
    "    if user_data.empty:\n",
    "        return\n",
    "\n",
    "    # Get unique n values\n",
    "    n_values = sorted(user_data['n'].unique())\n",
    "    if len(n_values) == 0:\n",
    "        return\n",
    "\n",
    "    # Create subplots (2x2 grid)\n",
    "    nplots = min(len(n_values), 4)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, n in enumerate(n_values[:nplots]):\n",
    "        data = user_data[user_data['n'] == n].copy()\n",
    "        if data.empty:\n",
    "            continue\n",
    "\n",
    "        grouped = data.groupby(['sparsity','threads']).mean(numeric_only=True).reset_index()\n",
    "        ax = axes[idx]\n",
    "\n",
    "        sparsities = sorted(grouped['sparsity'].unique())\n",
    "        # Create offset for each sparsity level\n",
    "        offset_step = 0.15\n",
    "        offsets = np.linspace(-offset_step * (len(sparsities)-1)/2,\n",
    "                              offset_step * (len(sparsities)-1)/2,\n",
    "                              len(sparsities))\n",
    "\n",
    "        # Calculate baseline uncertainty from all sequential runs\n",
    "        seq_data = data[data['threads_label'].str.lower() == 'sequential']\n",
    "        if not seq_data.empty:\n",
    "            baseline_mean = seq_data['time_spmv_total'].mean()\n",
    "            baseline_std = seq_data['time_spmv_total'].std()\n",
    "            if baseline_mean > 0 and not np.isnan(baseline_std):\n",
    "                baseline_uncertainty = baseline_std / baseline_mean\n",
    "            else:\n",
    "                baseline_uncertainty = 0\n",
    "        else:\n",
    "            baseline_uncertainty = 0\n",
    "\n",
    "        for sparsity_idx, (s, sdata) in enumerate(grouped.groupby('sparsity')):\n",
    "            sdata = sdata.sort_values('threads')\n",
    "            # Use raw data for baseline detection (sequential CSR)\n",
    "            raw_s = data[data['sparsity'] == s]\n",
    "            baseline_raw = raw_s[raw_s['threads_label'].str.lower() == 'sequential']\n",
    "            if not baseline_raw.empty:\n",
    "                b = baseline_raw['time_spmv_total'].mean()\n",
    "                sb = baseline_raw['time_spmv_total'].std() if baseline_raw['time_spmv_total'].std() else 0.0\n",
    "            else:\n",
    "                b_series = raw_s[raw_s['threads'] == 1]['time_spmv_total']\n",
    "                if b_series.empty or b_series.mean() == 0:\n",
    "                    continue\n",
    "                b = b_series.mean()\n",
    "                sb = b_series.std() if not np.isnan(b_series.std()) else 0.0\n",
    "\n",
    "            # Compute means and stds for CSR at each thread (excluding sequential)\n",
    "            s_mean = sdata[sdata['threads'] != -1].groupby('threads')['time_spmv_total'].mean().reset_index()\n",
    "            s_std = sdata[sdata['threads'] != -1].groupby('threads')['time_spmv_total'].std().reset_index().fillna(0)\n",
    "            s_mean = s_mean.sort_values('threads').reset_index(drop=True)\n",
    "            s_std = s_std.set_index('threads').reindex(s_mean['threads']).reset_index(drop=True)\n",
    "\n",
    "            if s_mean.empty:\n",
    "                continue\n",
    "\n",
    "            m = s_mean['time_spmv_total'].values\n",
    "            sm = s_std['time_spmv_total'].values\n",
    "            speedup_mean = b / m\n",
    "            # Propagate uncertainty: var = (sb^2)/(m^2) + (b^2)*(sm^2)/(m^4)\n",
    "            var = (sb**2) / (m**2) + (b**2) * (sm**2) / (m**4)\n",
    "            speedup_std = np.sqrt(var)\n",
    "            speedup_std = np.maximum(speedup_std, 0)\n",
    "\n",
    "            # Apply offset to x-axis positions\n",
    "            x_pos = s_mean['threads'].values + offsets[sparsity_idx]\n",
    "            ax.errorbar(x_pos, speedup_mean, yerr=speedup_std,\n",
    "                       marker='o', label=f's={s}%', capsize=4)\n",
    "\n",
    "        # Add baseline reference at 1.0\n",
    "        ax.axhline(y=1.0, color='r', linestyle='--', alpha=0.5, label='No speedup (1.0x)')\n",
    "        \n",
    "        # Add baseline uncertainty band\n",
    "        if baseline_uncertainty > 0:\n",
    "            ax.axhspan(1.0 - baseline_uncertainty, 1.0 + baseline_uncertainty, \n",
    "                       color='red', alpha=0.1, label='Sequential Uncertainty')\n",
    "        \n",
    "        # Show thread counts on the x-axis (excluding sequential)\n",
    "        all_threads = sorted([t for t in grouped['threads'].unique() if t != -1])\n",
    "        ax.set_xticks(all_threads)\n",
    "        ax.set_xticklabels([str(int(t)) for t in all_threads])\n",
    "        ax.set_xlabel('Threads')\n",
    "        ax.set_ylabel('Speedup (x)')\n",
    "        ax.set_title(f'n={n}')\n",
    "        ax.grid(True, alpha=0.25)\n",
    "        ax.legend(fontsize=8)\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for idx in range(nplots, 4):\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "    fig.suptitle(f'CSR SpMV Parallel Speedup vs Thread Count (User: {user})', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fname = os.path.join(PLOTS_DIR, f'csr_parallel_speedup_all_{user}.png')\n",
    "    fig.savefig(fname, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# Dense vs CSR speedup (dense / csr) with same formatting\n",
    "def plot_dense_vs_csr_subplots(df, user):\n",
    "    user_data = df[df['user'] == user].copy()\n",
    "    if user_data.empty:\n",
    "        return\n",
    "\n",
    "    # Get unique n values\n",
    "    n_values = sorted(user_data['n'].unique())\n",
    "    if len(n_values) == 0:\n",
    "        return\n",
    "\n",
    "    # Create subplots (2x2 grid)\n",
    "    nplots = min(len(n_values), 4)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, n in enumerate(n_values[:nplots]):\n",
    "        data = user_data[user_data['n'] == n].copy()\n",
    "        if data.empty:\n",
    "            continue\n",
    "\n",
    "        grouped = data.groupby(['sparsity','threads']).mean(numeric_only=True).reset_index()\n",
    "        ax = axes[idx]\n",
    "\n",
    "        sparsities = sorted(grouped['sparsity'].unique())\n",
    "        # Create offset for each sparsity level\n",
    "        offset_step = 0.15\n",
    "        offsets = np.linspace(-offset_step * (len(sparsities)-1)/2,\n",
    "                              offset_step * (len(sparsities)-1)/2,\n",
    "                              len(sparsities))\n",
    "\n",
    "        # Calculate baseline uncertainty from all sequential runs\n",
    "        seq_data = data[data['threads_label'].str.lower() == 'sequential']\n",
    "        if not seq_data.empty:\n",
    "            baseline_mean = seq_data['time_spmv_total'].mean()\n",
    "            baseline_std = seq_data['time_spmv_total'].std()\n",
    "            if baseline_mean > 0 and not np.isnan(baseline_std):\n",
    "                baseline_uncertainty = baseline_std / baseline_mean\n",
    "            else:\n",
    "                baseline_uncertainty = 0\n",
    "        else:\n",
    "            baseline_uncertainty = 0\n",
    "\n",
    "        for sparsity_idx, (s, sdata) in enumerate(grouped.groupby('sparsity')):\n",
    "            sdata = sdata.sort_values('threads')\n",
    "            # Use raw data for CSR baseline detection (sequential CSR)\n",
    "            raw_s = data[data['sparsity'] == s]\n",
    "            baseline_raw = raw_s[raw_s['threads_label'].str.lower() == 'sequential']\n",
    "            if not baseline_raw.empty:\n",
    "                b = baseline_raw['time_spmv_total'].mean()\n",
    "                sb = baseline_raw['time_spmv_total'].std() if baseline_raw['time_spmv_total'].std() else 0.0\n",
    "            else:\n",
    "                b_series = raw_s[raw_s['threads'] == 1]['time_spmv_total']\n",
    "                if b_series.empty or b_series.mean() == 0:\n",
    "                    continue\n",
    "                b = b_series.mean()\n",
    "                sb = b_series.std() if not np.isnan(b_series.std()) else 0.0\n",
    "\n",
    "            # Compute means and stds for Dense at each thread (excluding sequential)\n",
    "            s_mean = sdata[sdata['threads'] != -1].groupby('threads')['time_dense_total'].mean().reset_index()\n",
    "            s_std = sdata[sdata['threads'] != -1].groupby('threads')['time_dense_total'].std().reset_index().fillna(0)\n",
    "            s_mean = s_mean.sort_values('threads').reset_index(drop=True)\n",
    "            s_std = s_std.set_index('threads').reindex(s_mean['threads']).reset_index(drop=True)\n",
    "\n",
    "            if s_mean.empty:\n",
    "                continue\n",
    "\n",
    "            m = s_mean['time_dense_total'].values\n",
    "            sm = s_std['time_dense_total'].values\n",
    "            speedup_mean = m / b\n",
    "            # Propagate uncertainty: var = (sm^2)/(b^2) + (m^2)*(sb^2)/(b^4)\n",
    "            var = (sm**2) / (b**2) + (m**2) * (sb**2) / (b**4)\n",
    "            speedup_std = np.sqrt(var)\n",
    "            speedup_std = np.maximum(speedup_std, 0)\n",
    "\n",
    "            x_pos = s_mean['threads'].values + offsets[sparsity_idx]\n",
    "            ax.errorbar(x_pos, speedup_mean, yerr=speedup_std,\n",
    "                       marker='o', label=f's={s}%', capsize=4)\n",
    "\n",
    "        # Add baseline reference at 1.0\n",
    "        ax.axhline(y=1.0, color='r', linestyle='--', alpha=0.5, label='Equal performance (1.0x)')\n",
    "        \n",
    "        # Add baseline uncertainty band\n",
    "        if baseline_uncertainty > 0:\n",
    "            ax.axhspan(1.0 - baseline_uncertainty, 1.0 + baseline_uncertainty, \n",
    "                       color='red', alpha=0.1, label='Sequential Uncertainty')\n",
    "        \n",
    "        # Show thread counts on the x-axis (excluding sequential)\n",
    "        all_threads = sorted([t for t in grouped['threads'].unique() if t != -1])\n",
    "        ax.set_xticks(all_threads)\n",
    "        ax.set_xticklabels([str(int(t)) for t in all_threads])\n",
    "        ax.set_xlabel('Threads')\n",
    "        ax.set_ylabel('Speedup (Dense / CSR)')\n",
    "        ax.set_title(f'n={n}')\n",
    "        ax.grid(True, alpha=0.25)\n",
    "        ax.legend(fontsize=8)\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for idx in range(nplots, 4):\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "    fig.suptitle(f'Dense vs CSR Performance Ratio (User: {user})', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fname = os.path.join(PLOTS_DIR, f'dense_vs_csr_all_{user}.png')\n",
    "    fig.savefig(fname, dpi=300)\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91370a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating plots for user: ea24205\n",
      "Generating plots for user: marr\n",
      "Generating plots for user: phoebus\n",
      "All plots generated and saved to /home/marr/threads/Thread-Experiments/2_2_sparse_array_vector_multiplication/plots\n"
     ]
    }
   ],
   "source": [
    "# Generate plots per user\n",
    "for user in sorted(res['user'].unique()):\n",
    "    user_df = res[res['user'] == user]\n",
    "    print(f'Generating plots for user: {user}')\n",
    "\n",
    "    plot_timing_breakdown_multiplots(res, user)\n",
    "    plot_compact_timing_subplots(res, user)\n",
    "    plot_csr_parallel_speedup_subplots(res, user)\n",
    "    plot_dense_vs_csr_subplots(res, user)\n",
    "\n",
    "print('All plots generated and saved to', PLOTS_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
