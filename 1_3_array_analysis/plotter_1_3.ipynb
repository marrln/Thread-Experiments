{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d3ac64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: plots/plot_1_3_marr_time_total.png\n",
      "Saved: plots/plot_1_3_marr_time_compute.png\n",
      "Saved: plots/plot_1_3_marr_time_compute.png\n",
      "Saved: plots/plot_1_3_marr_speedup_overlay.png\n",
      "Saved: plots/plot_1_3_marr_speedup_overlay.png\n",
      "Saved: plots/plot_1_3_marr_compute_speedup_overlay.png\n",
      "Skipping all-users overlay generation: only 1 user(s) present.\n",
      "\n",
      "Overlay speedup plots generated for individual users (total + compute).\n",
      "Saved: plots/plot_1_3_marr_compute_speedup_overlay.png\n",
      "Skipping all-users overlay generation: only 1 user(s) present.\n",
      "\n",
      "Overlay speedup plots generated for individual users (total + compute).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load results CSV\n",
    "CSV_FILE = \"results_1.3.csv\"\n",
    "res_df = pd.read_csv(CSV_FILE)\n",
    "\n",
    "# Ensure plots directory exists\n",
    "os.makedirs('plots', exist_ok=True)\n",
    "\n",
    "# Normalize dataframe\n",
    "df = res_df.copy()\n",
    "df['user'] = df.get('user', 'unknown')\n",
    "df['version'] = df['version'].astype(str).str.strip().str.lower()\n",
    "df['size'] = pd.to_numeric(df.get('size'), errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "time_cols = [\"time_init\", \"time_compute\", \"time_thread_create\", \"time_thread_join\", \"time_cleanup\", \"time_total\"]\n",
    "for col in time_cols:\n",
    "    df[col] = pd.to_numeric(df.get(col), errors='coerce').fillna(0)\n",
    "\n",
    "unique_users = sorted(df[\"user\"].unique())\n",
    "unique_sizes = sorted(df[\"size\"].unique())\n",
    "versions = [\"sequential\", \"parallel_unpadded\", \"parallel_padded\", \"parallel_local_accum\"]\n",
    "colors = {\n",
    "    \"sequential\": \"#7f7f7f\",\n",
    "    \"parallel_unpadded\": \"#ff7f0e\",\n",
    "    \"parallel_padded\": \"#2ca02c\",\n",
    "    \"parallel_local_accum\": \"#d62728\"\n",
    "}\n",
    "\n",
    "# Track saved files to avoid double-saving within one run\n",
    "_saved_plot_paths = set()\n",
    "\n",
    "def size_label(n):\n",
    "    return f\"{n//1_000_000}M\" if n >= 1_000_000 else f\"{n//1000}K\" if n >= 1000 else str(n)\n",
    "\n",
    "# --- Function to overlay speedups with error propagation ---\n",
    "def plot_speedup_overlay(seq_means, par_means_dict, sizes, title, outpath, seq_stds=None, par_stds_dict=None):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    fig.suptitle(title, fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "    x = np.arange(len(sizes))\n",
    "    for par_version, par_means in par_means_dict.items():\n",
    "        # Convert to numpy arrays\n",
    "        seq = np.asarray(seq_means, dtype=float)\n",
    "        par = np.asarray(par_means, dtype=float)\n",
    "\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            speedup = np.where(par > 0, seq / par, np.nan)\n",
    "\n",
    "        # Error propagation for S = A / B: var(S) ≈ S^2 * ( (σ_A/μ_A)^2 + (σ_B/μ_B)^2 )\n",
    "        speedup_err = np.full_like(speedup, np.nan)\n",
    "        if seq_stds is not None and par_stds_dict is not None and par_version in par_stds_dict:\n",
    "            seq_s = np.asarray(seq_stds, dtype=float)\n",
    "            par_s = np.asarray(par_stds_dict[par_version], dtype=float)\n",
    "            # Avoid division by zero; only compute where means > 0\n",
    "            valid = (seq > 0) & (par > 0)\n",
    "            rel_sq = np.zeros_like(speedup)\n",
    "            # compute relative squared errors safely\n",
    "            rel_sq[valid] = (seq_s[valid] / seq[valid]) ** 2 + (par_s[valid] / par[valid]) ** 2\n",
    "            speedup_err[valid] = np.abs(speedup[valid]) * np.sqrt(rel_sq[valid])\n",
    "\n",
    "        # Plot mean\n",
    "        ax.plot(x, speedup, marker='o', linewidth=2, markersize=8,\n",
    "                label=par_version.replace('_', ' ').capitalize(), color=colors.get(par_version, '#444'))\n",
    "\n",
    "        # Plot error band if available\n",
    "        if np.any(np.isfinite(speedup_err)):\n",
    "            lower = speedup - speedup_err\n",
    "            upper = speedup + speedup_err\n",
    "            ax.fill_between(x, lower, upper, alpha=0.2, color=colors.get(par_version, '#444'))\n",
    "            # also show small errorbars on markers\n",
    "            ax.errorbar(x, speedup, yerr=speedup_err, fmt='none', ecolor=colors.get(par_version, '#444'), capsize=4, alpha=0.8)\n",
    "\n",
    "    ax.set_xlabel(\"Array Size\", fontsize=11)\n",
    "    ax.set_ylabel(\"Speedup\", fontsize=11)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([size_label(s) for s in sizes])\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(fontsize=10)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Avoid saving same path twice in one run\n",
    "    if outpath not in _saved_plot_paths:\n",
    "        fig.savefig(outpath, dpi=300, bbox_inches=\"tight\")\n",
    "        _saved_plot_paths.add(outpath)\n",
    "        print(f\"Saved: {outpath}\")\n",
    "    else:\n",
    "        print(f\"Skipped duplicate save: {outpath}\")\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "# --- Per-user plots ---\n",
    "for user in unique_users:\n",
    "    user_df = df[df[\"user\"] == user].copy()\n",
    "    if user_df.empty:\n",
    "        continue\n",
    "\n",
    "    stats = user_df.groupby([\"version\", \"size\"])[time_cols].agg([\"mean\", \"std\"]).reset_index()\n",
    "    stats.columns = [\"_\".join(c).strip(\"_\") for c in stats.columns]\n",
    "\n",
    "    # Timing plots (same as before)\n",
    "    for metric in [\"time_total\", \"time_compute\"]:\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        fig.suptitle(f\"Array Analysis — {metric.replace('time_', '').replace('_', ' ').title()} — User: {user}\", fontsize=14, fontweight=\"bold\")\n",
    "        jitter_offset = np.linspace(-0.2, 0.2, len(versions))\n",
    "\n",
    "        for idx, version in enumerate(versions):\n",
    "            version_stats = stats[stats[\"version\"] == version]\n",
    "            if version_stats.empty: continue\n",
    "            x_jitter = np.arange(len(unique_sizes)) + jitter_offset[idx]\n",
    "            y_mean = version_stats[f\"{metric}_mean\"].values\n",
    "            y_std = version_stats[f\"{metric}_std\"].values\n",
    "            ax.errorbar(x_jitter, y_mean, yerr=y_std, marker='o', label=version.replace('_', ' ').capitalize(),\n",
    "                        linewidth=2, capsize=5, linestyle='-', alpha=0.8, color=colors.get(version, \"#444\"))\n",
    "\n",
    "        ax.set_xlabel(\"Array Size\", fontsize=11)\n",
    "        ax.set_ylabel(f\"{metric.replace('time_', '').replace('_', ' ').title()} (s)\", fontsize=11)\n",
    "        ax.set_xticks(range(len(unique_sizes)))\n",
    "        ax.set_xticklabels([size_label(s) for s in unique_sizes])\n",
    "        ax.legend(fontsize=10)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        outpath = f\"plots/plot_1_3_{user}_{metric}.png\"\n",
    "        if outpath not in _saved_plot_paths:\n",
    "            fig.savefig(outpath, dpi=300, bbox_inches=\"tight\")\n",
    "            _saved_plot_paths.add(outpath)\n",
    "            print(f\"Saved: {outpath}\")\n",
    "        else:\n",
    "            print(f\"Skipped duplicate save: {outpath}\")\n",
    "        plt.close(fig)\n",
    "\n",
    "    # --- Overlay speedup plot (total) ---\n",
    "    seq_stats = stats[stats[\"version\"] == \"sequential\"]\n",
    "    common_sizes = sorted(set(seq_stats[\"size\"]) & set(stats[\"size\"]))\n",
    "    if not common_sizes: continue\n",
    "\n",
    "    seq_times = seq_stats[seq_stats[\"size\"].isin(common_sizes)].set_index(\"size\")[\"time_total_mean\"].reindex(common_sizes).values\n",
    "    seq_times_std = seq_stats[seq_stats[\"size\"].isin(common_sizes)].set_index(\"size\")[\"time_total_std\"].reindex(common_sizes).values\n",
    "\n",
    "    par_times_dict = {}\n",
    "    par_times_std_dict = {}\n",
    "    for par_version in [\"parallel_unpadded\", \"parallel_padded\", \"parallel_local_accum\"]:\n",
    "        par_times = stats[(stats[\"version\"] == par_version) & (stats[\"size\"].isin(common_sizes))]\n",
    "        par_times = par_times.set_index(\"size\")[\"time_total_mean\"].reindex(common_sizes).values\n",
    "        par_times_std = stats[(stats[\"version\"] == par_version) & (stats[\"size\"].isin(common_sizes))].set_index(\"size\")[\"time_total_std\"].reindex(common_sizes).values\n",
    "        par_times_dict[par_version] = par_times\n",
    "        par_times_std_dict[par_version] = par_times_std\n",
    "\n",
    "    plot_speedup_overlay(seq_times, par_times_dict, common_sizes,\n",
    "                         f\"Array Analysis — Total-time Speedup — User: {user}\",\n",
    "                         f\"plots/plot_1_3_{user}_speedup_overlay.png\",\n",
    "                         seq_stds=seq_times_std, par_stds_dict=par_times_std_dict)\n",
    "\n",
    "    # --- Overlay compute-time speedup for this user ---\n",
    "    seq_times_compute = seq_stats[seq_stats[\"size\"].isin(common_sizes)].set_index(\"size\")[\"time_compute_mean\"].reindex(common_sizes).values\n",
    "    seq_times_compute_std = seq_stats[seq_stats[\"size\"].isin(common_sizes)].set_index(\"size\")[\"time_compute_std\"].reindex(common_sizes).values\n",
    "    par_times_compute_dict = {}\n",
    "    par_times_compute_std_dict = {}\n",
    "    for par_version in [\"parallel_unpadded\", \"parallel_padded\", \"parallel_local_accum\"]:\n",
    "        par_times_c = stats[(stats[\"version\"] == par_version) & (stats[\"size\"].isin(common_sizes))]\n",
    "        par_times_c_mean = par_times_c.set_index(\"size\")[\"time_compute_mean\"].reindex(common_sizes).values\n",
    "        par_times_c_std = par_times_c.set_index(\"size\")[\"time_compute_std\"].reindex(common_sizes).values\n",
    "        par_times_compute_dict[par_version] = par_times_c_mean\n",
    "        par_times_compute_std_dict[par_version] = par_times_c_std\n",
    "\n",
    "    plot_speedup_overlay(seq_times_compute, par_times_compute_dict, common_sizes,\n",
    "                         f\"Array Analysis — Compute-time Speedup — User: {user}\",\n",
    "                         f\"plots/plot_1_3_{user}_compute_speedup_overlay.png\",\n",
    "                         seq_stds=seq_times_compute_std, par_stds_dict=par_times_compute_std_dict)\n",
    "\n",
    "# --- All-users combined overlay speedup ---\n",
    "if len(unique_users) > 1:\n",
    "    stats_all = df.groupby([\"version\", \"size\"])[time_cols].agg([\"mean\", \"std\"]).reset_index()\n",
    "    stats_all.columns = [\"_\".join(c).strip(\"_\") for c in stats_all.columns]\n",
    "\n",
    "    common_sizes = sorted(set(stats_all[stats_all[\"version\"] == \"sequential\"][\"size\"]) &\n",
    "                          set(stats_all[\"size\"]))\n",
    "    seq_times_all = stats_all[(stats_all[\"version\"] == \"sequential\") & (stats_all[\"size\"].isin(common_sizes))]\n",
    "    seq_times_all_mean = seq_times_all.set_index(\"size\")[\"time_total_mean\"].reindex(common_sizes).values\n",
    "    seq_times_all_std = seq_times_all.set_index(\"size\")[\"time_total_std\"].reindex(common_sizes).values\n",
    "\n",
    "    par_times_dict_all = {}\n",
    "    par_times_dict_all_std = {}\n",
    "    for par_version in [\"parallel_unpadded\", \"parallel_padded\", \"parallel_local_accum\"]:\n",
    "        par_times = stats_all[(stats_all[\"version\"] == par_version) & (stats_all[\"size\"].isin(common_sizes))]\n",
    "        par_times_mean = par_times.set_index(\"size\")[\"time_total_mean\"].reindex(common_sizes).values\n",
    "        par_times_std = par_times.set_index(\"size\")[\"time_total_std\"].reindex(common_sizes).values\n",
    "        par_times_dict_all[par_version] = par_times_mean\n",
    "        par_times_dict_all_std[par_version] = par_times_std\n",
    "\n",
    "    plot_speedup_overlay(seq_times_all_mean, par_times_dict_all, common_sizes,\n",
    "                         \"Array Analysis — Total-time Speedup — All Users\",\n",
    "                         \"plots/plot_1_3_all_users_speedup_overlay.png\",\n",
    "                         seq_stds=seq_times_all_std, par_stds_dict=par_times_dict_all_std)\n",
    "\n",
    "    # --- All-users compute-time overlay speedup ---\n",
    "    seq_times_all_compute = stats_all[(stats_all[\"version\"] == \"sequential\") & (stats_all[\"size\"].isin(common_sizes))]\n",
    "    seq_times_all_compute_mean = seq_times_all_compute.set_index(\"size\")[\"time_compute_mean\"].reindex(common_sizes).values\n",
    "    seq_times_all_compute_std = seq_times_all_compute.set_index(\"size\")[\"time_compute_std\"].reindex(common_sizes).values\n",
    "\n",
    "    par_times_dict_all_compute = {}\n",
    "    par_times_dict_all_compute_std = {}\n",
    "    for par_version in [\"parallel_unpadded\", \"parallel_padded\", \"parallel_local_accum\"]:\n",
    "        par_times_c = stats_all[(stats_all[\"version\"] == par_version) & (stats_all[\"size\"].isin(common_sizes))]\n",
    "        par_times_c_mean = par_times_c.set_index(\"size\")[\"time_compute_mean\"].reindex(common_sizes).values\n",
    "        par_times_c_std = par_times_c.set_index(\"size\")[\"time_compute_std\"].reindex(common_sizes).values\n",
    "        par_times_dict_all_compute[par_version] = par_times_c_mean\n",
    "        par_times_dict_all_compute_std[par_version] = par_times_c_std\n",
    "\n",
    "    plot_speedup_overlay(seq_times_all_compute_mean, par_times_dict_all_compute, common_sizes,\n",
    "                         \"Array Analysis — Compute-time Speedup — All Users\",\n",
    "                         \"plots/plot_1_3_all_users_compute_speedup_overlay.png\",\n",
    "                         seq_stds=seq_times_all_compute_std, par_stds_dict=par_times_dict_all_compute_std)\n",
    "else:\n",
    "    print(f\"Skipping all-users overlay generation: only {len(unique_users)} user(s) present.\")\n",
    "\n",
    "print(\"\\nOverlay speedup plots generated for individual users (total + compute).\")\n",
    "if len(unique_users) > 1:\n",
    "    print(\"All-users overlays generated (total + compute).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b820a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13506/2838813720.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  seq_total_mean = float(seq_row['time_total_mean']) if not seq_row.empty else np.nan\n",
      "/tmp/ipykernel_13506/2838813720.py:8: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  seq_total_std = float(seq_row['time_total_std']) if not seq_row.empty else np.nan\n",
      "/tmp/ipykernel_13506/2838813720.py:9: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  seq_compute_mean = float(seq_row['time_compute_mean']) if not seq_row.empty else np.nan\n",
      "/tmp/ipykernel_13506/2838813720.py:10: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  seq_compute_std = float(seq_row['time_compute_std']) if not seq_row.empty else np.nan\n",
      "/tmp/ipykernel_13506/2838813720.py:16: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  total_mean = float(r['time_total_mean'])\n",
      "/tmp/ipykernel_13506/2838813720.py:17: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  total_std = float(r['time_total_std'])\n",
      "/tmp/ipykernel_13506/2838813720.py:18: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  compute_mean = float(r['time_compute_mean'])\n",
      "/tmp/ipykernel_13506/2838813720.py:19: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  compute_std = float(r['time_compute_std'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>version</th>\n",
       "      <th>time_total_mean_ms</th>\n",
       "      <th>time_total_std_ms</th>\n",
       "      <th>time_compute_mean_ms</th>\n",
       "      <th>time_compute_std_ms</th>\n",
       "      <th>speedup_total_percentage</th>\n",
       "      <th>speedup_total_std_percentage</th>\n",
       "      <th>speedup_compute_percentage</th>\n",
       "      <th>speedup_compute_std_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>parallel_local_accum</td>\n",
       "      <td>20.4274</td>\n",
       "      <td>5.1007</td>\n",
       "      <td>17.5084</td>\n",
       "      <td>6.1092</td>\n",
       "      <td>14.3929</td>\n",
       "      <td>10.3912</td>\n",
       "      <td>1.4182</td>\n",
       "      <td>2.3008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100000</td>\n",
       "      <td>parallel_padded</td>\n",
       "      <td>20.9989</td>\n",
       "      <td>16.0372</td>\n",
       "      <td>17.5339</td>\n",
       "      <td>16.2802</td>\n",
       "      <td>14.0012</td>\n",
       "      <td>14.2932</td>\n",
       "      <td>1.4161</td>\n",
       "      <td>2.6005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100000</td>\n",
       "      <td>parallel_unpadded</td>\n",
       "      <td>18.1014</td>\n",
       "      <td>12.5421</td>\n",
       "      <td>13.3284</td>\n",
       "      <td>9.1030</td>\n",
       "      <td>16.2424</td>\n",
       "      <td>15.7390</td>\n",
       "      <td>1.8629</td>\n",
       "      <td>3.2141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100000</td>\n",
       "      <td>sequential</td>\n",
       "      <td>2.9401</td>\n",
       "      <td>1.9917</td>\n",
       "      <td>0.2483</td>\n",
       "      <td>0.3934</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>95.8005</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>224.0640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000000</td>\n",
       "      <td>parallel_local_accum</td>\n",
       "      <td>66.0104</td>\n",
       "      <td>8.7633</td>\n",
       "      <td>21.8648</td>\n",
       "      <td>7.1317</td>\n",
       "      <td>58.1328</td>\n",
       "      <td>31.6164</td>\n",
       "      <td>27.7780</td>\n",
       "      <td>21.6568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000000</td>\n",
       "      <td>parallel_padded</td>\n",
       "      <td>68.8097</td>\n",
       "      <td>34.9757</td>\n",
       "      <td>21.2836</td>\n",
       "      <td>16.5921</td>\n",
       "      <td>55.7679</td>\n",
       "      <td>40.8490</td>\n",
       "      <td>28.5365</td>\n",
       "      <td>30.0539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000000</td>\n",
       "      <td>parallel_unpadded</td>\n",
       "      <td>52.7144</td>\n",
       "      <td>28.2504</td>\n",
       "      <td>17.6882</td>\n",
       "      <td>12.0554</td>\n",
       "      <td>72.7955</td>\n",
       "      <td>54.7357</td>\n",
       "      <td>34.3370</td>\n",
       "      <td>33.7475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000000</td>\n",
       "      <td>sequential</td>\n",
       "      <td>38.3737</td>\n",
       "      <td>20.2388</td>\n",
       "      <td>6.0736</td>\n",
       "      <td>4.3009</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>74.5876</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.1444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10000000</td>\n",
       "      <td>parallel_local_accum</td>\n",
       "      <td>290.7294</td>\n",
       "      <td>107.4021</td>\n",
       "      <td>31.7720</td>\n",
       "      <td>22.0049</td>\n",
       "      <td>101.5648</td>\n",
       "      <td>63.9484</td>\n",
       "      <td>157.0329</td>\n",
       "      <td>141.8024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10000000</td>\n",
       "      <td>parallel_padded</td>\n",
       "      <td>254.2311</td>\n",
       "      <td>127.9009</td>\n",
       "      <td>26.7957</td>\n",
       "      <td>17.4965</td>\n",
       "      <td>116.1457</td>\n",
       "      <td>83.1932</td>\n",
       "      <td>186.1959</td>\n",
       "      <td>162.5466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10000000</td>\n",
       "      <td>parallel_unpadded</td>\n",
       "      <td>275.9346</td>\n",
       "      <td>116.8166</td>\n",
       "      <td>34.2388</td>\n",
       "      <td>22.0022</td>\n",
       "      <td>107.0104</td>\n",
       "      <td>70.9170</td>\n",
       "      <td>145.7192</td>\n",
       "      <td>126.0867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10000000</td>\n",
       "      <td>sequential</td>\n",
       "      <td>295.2786</td>\n",
       "      <td>150.5524</td>\n",
       "      <td>49.8925</td>\n",
       "      <td>28.9096</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>72.1059</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>81.9449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50000000</td>\n",
       "      <td>parallel_local_accum</td>\n",
       "      <td>1097.5318</td>\n",
       "      <td>482.8285</td>\n",
       "      <td>80.4804</td>\n",
       "      <td>39.6365</td>\n",
       "      <td>64.5428</td>\n",
       "      <td>41.7491</td>\n",
       "      <td>122.6214</td>\n",
       "      <td>85.6484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50000000</td>\n",
       "      <td>parallel_padded</td>\n",
       "      <td>738.6871</td>\n",
       "      <td>353.2116</td>\n",
       "      <td>95.7070</td>\n",
       "      <td>43.4535</td>\n",
       "      <td>95.8969</td>\n",
       "      <td>64.5802</td>\n",
       "      <td>103.1128</td>\n",
       "      <td>69.2820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50000000</td>\n",
       "      <td>parallel_unpadded</td>\n",
       "      <td>794.3450</td>\n",
       "      <td>449.0110</td>\n",
       "      <td>95.7516</td>\n",
       "      <td>111.1836</td>\n",
       "      <td>89.1776</td>\n",
       "      <td>65.7979</td>\n",
       "      <td>103.0648</td>\n",
       "      <td>130.1079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50000000</td>\n",
       "      <td>sequential</td>\n",
       "      <td>708.3780</td>\n",
       "      <td>335.9196</td>\n",
       "      <td>98.6862</td>\n",
       "      <td>48.8787</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>67.0633</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>70.0452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100000000</td>\n",
       "      <td>parallel_local_accum</td>\n",
       "      <td>1232.1340</td>\n",
       "      <td>202.3717</td>\n",
       "      <td>103.3418</td>\n",
       "      <td>42.9312</td>\n",
       "      <td>98.2050</td>\n",
       "      <td>36.1239</td>\n",
       "      <td>166.2529</td>\n",
       "      <td>74.9490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100000000</td>\n",
       "      <td>parallel_padded</td>\n",
       "      <td>1127.1994</td>\n",
       "      <td>586.1938</td>\n",
       "      <td>164.7602</td>\n",
       "      <td>124.1100</td>\n",
       "      <td>107.3472</td>\n",
       "      <td>66.0667</td>\n",
       "      <td>104.2780</td>\n",
       "      <td>80.6438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100000000</td>\n",
       "      <td>parallel_unpadded</td>\n",
       "      <td>981.5359</td>\n",
       "      <td>310.4206</td>\n",
       "      <td>136.5246</td>\n",
       "      <td>66.8194</td>\n",
       "      <td>123.2779</td>\n",
       "      <td>56.2708</td>\n",
       "      <td>125.8445</td>\n",
       "      <td>65.4141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100000000</td>\n",
       "      <td>sequential</td>\n",
       "      <td>1210.0168</td>\n",
       "      <td>398.2608</td>\n",
       "      <td>171.8087</td>\n",
       "      <td>30.0791</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>46.5469</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>24.7591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         size               version  time_total_mean_ms  time_total_std_ms  \\\n",
       "0      100000  parallel_local_accum             20.4274             5.1007   \n",
       "1      100000       parallel_padded             20.9989            16.0372   \n",
       "2      100000     parallel_unpadded             18.1014            12.5421   \n",
       "3      100000            sequential              2.9401             1.9917   \n",
       "4     1000000  parallel_local_accum             66.0104             8.7633   \n",
       "5     1000000       parallel_padded             68.8097            34.9757   \n",
       "6     1000000     parallel_unpadded             52.7144            28.2504   \n",
       "7     1000000            sequential             38.3737            20.2388   \n",
       "8    10000000  parallel_local_accum            290.7294           107.4021   \n",
       "9    10000000       parallel_padded            254.2311           127.9009   \n",
       "10   10000000     parallel_unpadded            275.9346           116.8166   \n",
       "11   10000000            sequential            295.2786           150.5524   \n",
       "12   50000000  parallel_local_accum           1097.5318           482.8285   \n",
       "13   50000000       parallel_padded            738.6871           353.2116   \n",
       "14   50000000     parallel_unpadded            794.3450           449.0110   \n",
       "15   50000000            sequential            708.3780           335.9196   \n",
       "16  100000000  parallel_local_accum           1232.1340           202.3717   \n",
       "17  100000000       parallel_padded           1127.1994           586.1938   \n",
       "18  100000000     parallel_unpadded            981.5359           310.4206   \n",
       "19  100000000            sequential           1210.0168           398.2608   \n",
       "\n",
       "    time_compute_mean_ms  time_compute_std_ms  speedup_total_percentage  \\\n",
       "0                17.5084               6.1092                   14.3929   \n",
       "1                17.5339              16.2802                   14.0012   \n",
       "2                13.3284               9.1030                   16.2424   \n",
       "3                 0.2483               0.3934                  100.0000   \n",
       "4                21.8648               7.1317                   58.1328   \n",
       "5                21.2836              16.5921                   55.7679   \n",
       "6                17.6882              12.0554                   72.7955   \n",
       "7                 6.0736               4.3009                  100.0000   \n",
       "8                31.7720              22.0049                  101.5648   \n",
       "9                26.7957              17.4965                  116.1457   \n",
       "10               34.2388              22.0022                  107.0104   \n",
       "11               49.8925              28.9096                  100.0000   \n",
       "12               80.4804              39.6365                   64.5428   \n",
       "13               95.7070              43.4535                   95.8969   \n",
       "14               95.7516             111.1836                   89.1776   \n",
       "15               98.6862              48.8787                  100.0000   \n",
       "16              103.3418              42.9312                   98.2050   \n",
       "17              164.7602             124.1100                  107.3472   \n",
       "18              136.5246              66.8194                  123.2779   \n",
       "19              171.8087              30.0791                  100.0000   \n",
       "\n",
       "    speedup_total_std_percentage  speedup_compute_percentage  \\\n",
       "0                        10.3912                      1.4182   \n",
       "1                        14.2932                      1.4161   \n",
       "2                        15.7390                      1.8629   \n",
       "3                        95.8005                    100.0000   \n",
       "4                        31.6164                     27.7780   \n",
       "5                        40.8490                     28.5365   \n",
       "6                        54.7357                     34.3370   \n",
       "7                        74.5876                    100.0000   \n",
       "8                        63.9484                    157.0329   \n",
       "9                        83.1932                    186.1959   \n",
       "10                       70.9170                    145.7192   \n",
       "11                       72.1059                    100.0000   \n",
       "12                       41.7491                    122.6214   \n",
       "13                       64.5802                    103.1128   \n",
       "14                       65.7979                    103.0648   \n",
       "15                       67.0633                    100.0000   \n",
       "16                       36.1239                    166.2529   \n",
       "17                       66.0667                    104.2780   \n",
       "18                       56.2708                    125.8445   \n",
       "19                       46.5469                    100.0000   \n",
       "\n",
       "    speedup_compute_std_percentage  \n",
       "0                           2.3008  \n",
       "1                           2.6005  \n",
       "2                           3.2141  \n",
       "3                         224.0640  \n",
       "4                          21.6568  \n",
       "5                          30.0539  \n",
       "6                          33.7475  \n",
       "7                         100.1444  \n",
       "8                         141.8024  \n",
       "9                         162.5466  \n",
       "10                        126.0867  \n",
       "11                         81.9449  \n",
       "12                         85.6484  \n",
       "13                         69.2820  \n",
       "14                        130.1079  \n",
       "15                         70.0452  \n",
       "16                         74.9490  \n",
       "17                         80.6438  \n",
       "18                         65.4141  \n",
       "19                         24.7591  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build a concise summary table per size/version with speedups (and propagated std)\n",
    "src = stats_all if 'stats_all' in globals() and isinstance(stats_all, pd.DataFrame) and not stats_all.empty else stats\n",
    "\n",
    "rows = []\n",
    "for s in sorted(src['size'].unique()):\n",
    "    seq_row = src[(src['version'] == 'sequential') & (src['size'] == s)]\n",
    "    seq_total_mean = float(seq_row['time_total_mean']) if not seq_row.empty else np.nan\n",
    "    seq_total_std = float(seq_row['time_total_std']) if not seq_row.empty else np.nan\n",
    "    seq_compute_mean = float(seq_row['time_compute_mean']) if not seq_row.empty else np.nan\n",
    "    seq_compute_std = float(seq_row['time_compute_std']) if not seq_row.empty else np.nan\n",
    "\n",
    "    for v in sorted(src['version'].unique()):\n",
    "        r = src[(src['version'] == v) & (src['size'] == s)]\n",
    "        if r.empty:\n",
    "            continue\n",
    "        total_mean = float(r['time_total_mean'])\n",
    "        total_std = float(r['time_total_std'])\n",
    "        compute_mean = float(r['time_compute_mean'])\n",
    "        compute_std = float(r['time_compute_std'])\n",
    "\n",
    "        # speedup = sequential / current\n",
    "        def compute_speedup(mu_a, sigma_a, mu_b, sigma_b):\n",
    "            if mu_a > 0 and mu_b > 0:\n",
    "                s = mu_a / mu_b\n",
    "                rel_sq = (sigma_a / mu_a) ** 2 + (sigma_b / mu_b) ** 2\n",
    "                s_std = abs(s) * np.sqrt(rel_sq)\n",
    "                return s, s_std\n",
    "            return np.nan, np.nan\n",
    "\n",
    "        speedup_total_mean, speedup_total_std = compute_speedup(seq_total_mean, seq_total_std, total_mean, total_std)\n",
    "        speedup_compute_mean, speedup_compute_std = compute_speedup(seq_compute_mean, seq_compute_std, compute_mean, compute_std)\n",
    "\n",
    "        rows.append({\n",
    "            'size': s,\n",
    "            'version': v,\n",
    "            'time_total_mean_ms': total_mean * 1000,\n",
    "            'time_total_std_ms': total_std * 1000,\n",
    "            'time_compute_mean_ms': compute_mean * 1000,\n",
    "            'time_compute_std_ms': compute_std * 1000,\n",
    "            'speedup_total_percentage': speedup_total_mean * 100,\n",
    "            'speedup_total_std_percentage': speedup_total_std * 100,\n",
    "            'speedup_compute_percentage': speedup_compute_mean * 100,\n",
    "            'speedup_compute_std_percentage': speedup_compute_std * 100\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(rows).sort_values(['size', 'version']).reset_index(drop=True)\n",
    "\n",
    "# nicer formatting for display in Jupyter\n",
    "pd.set_option('display.precision', 4)\n",
    "display(summary_df)\n",
    "\n",
    "# # save CSV for later reference\n",
    "# out_csv = \"plots/summary_table.csv\"\n",
    "# summary_df.to_csv(out_csv, index=False)\n",
    "# print(f\"Saved summary to: {out_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
