{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d3ac64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: plots/plot_1_3_ea24205_time_total.png\n",
      "Saved: plots/plot_1_3_ea24205_time_compute.png\n",
      "Saved: plots/plot_1_3_ea24205_speedup_overlay.png\n",
      "Saved: plots/plot_1_3_ea24205_compute_speedup_overlay.png\n",
      "Saved: plots/plot_1_3_phoebus_time_total.png\n",
      "Saved: plots/plot_1_3_phoebus_time_compute.png\n",
      "Saved: plots/plot_1_3_phoebus_speedup_overlay.png\n",
      "Saved: plots/plot_1_3_phoebus_compute_speedup_overlay.png\n",
      "\n",
      "Overlay speedup plots generated for individual users (total + compute).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load results CSV\n",
    "CSV_FILE = \"results_1.3.csv\"\n",
    "res_df = pd.read_csv(CSV_FILE)\n",
    "\n",
    "# Ensure plots directory exists\n",
    "os.makedirs('plots', exist_ok=True)\n",
    "\n",
    "# Normalize dataframe\n",
    "df = res_df.copy()\n",
    "df['user'] = df.get('user', 'unknown')\n",
    "df['version'] = df['version'].astype(str).str.strip().str.lower()\n",
    "df['size'] = pd.to_numeric(df.get('size'), errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "time_cols = [\"time_init\", \"time_compute\", \"time_thread_create\", \"time_thread_join\", \"time_cleanup\", \"time_total\"]\n",
    "for col in time_cols:\n",
    "    df[col] = pd.to_numeric(df.get(col), errors='coerce').fillna(0)\n",
    "\n",
    "unique_users = sorted(df[\"user\"].unique())\n",
    "unique_sizes = sorted(df[\"size\"].unique())\n",
    "versions = [\"sequential\", \"parallel_unpadded\", \"parallel_padded\", \"parallel_local_accum\"]\n",
    "colors = {\n",
    "    \"sequential\": \"#7f7f7f\",\n",
    "    \"parallel_unpadded\": \"#ff7f0e\",\n",
    "    \"parallel_padded\": \"#2ca02c\",\n",
    "    \"parallel_local_accum\": \"#d62728\"\n",
    "}\n",
    "\n",
    "# Track saved files to avoid double-saving within one run\n",
    "_saved_plot_paths = set()\n",
    "\n",
    "def size_label(n):\n",
    "    return f\"{n//1_000_000}M\" if n >= 1_000_000 else f\"{n//1000}K\" if n >= 1000 else str(n)\n",
    "\n",
    "# --- Function to overlay speedups with error propagation ---\n",
    "def plot_speedup_overlay(seq_means, par_means_dict, sizes, title, outpath, seq_stds=None, par_stds_dict=None):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    fig.suptitle(title, fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "    x = np.arange(len(sizes))\n",
    "    for par_version, par_means in par_means_dict.items():\n",
    "        # Convert to numpy arrays\n",
    "        seq = np.asarray(seq_means, dtype=float)\n",
    "        par = np.asarray(par_means, dtype=float)\n",
    "\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            speedup = np.where(par > 0, seq / par, np.nan)\n",
    "\n",
    "        # Error propagation for S = A / B: var(S) ≈ S^2 * ( (σ_A/μ_A)^2 + (σ_B/μ_B)^2 )\n",
    "        speedup_err = np.full_like(speedup, np.nan)\n",
    "        if seq_stds is not None and par_stds_dict is not None and par_version in par_stds_dict:\n",
    "            seq_s = np.asarray(seq_stds, dtype=float)\n",
    "            par_s = np.asarray(par_stds_dict[par_version], dtype=float)\n",
    "            # Avoid division by zero; only compute where means > 0\n",
    "            valid = (seq > 0) & (par > 0)\n",
    "            rel_sq = np.zeros_like(speedup)\n",
    "            # compute relative squared errors safely\n",
    "            rel_sq[valid] = (seq_s[valid] / seq[valid]) ** 2 + (par_s[valid] / par[valid]) ** 2\n",
    "            speedup_err[valid] = np.abs(speedup[valid]) * np.sqrt(rel_sq[valid])\n",
    "\n",
    "        # Plot mean\n",
    "        ax.plot(x, speedup, marker='o', linewidth=2, markersize=8,\n",
    "                label=par_version.replace('_', ' ').capitalize(), color=colors.get(par_version, '#444'))\n",
    "\n",
    "        # Plot error band if available\n",
    "        if np.any(np.isfinite(speedup_err)):\n",
    "            lower = speedup - speedup_err\n",
    "            upper = speedup + speedup_err\n",
    "            ax.fill_between(x, lower, upper, alpha=0.2, color=colors.get(par_version, '#444'))\n",
    "            # also show small errorbars on markers\n",
    "            ax.errorbar(x, speedup, yerr=speedup_err, fmt='none', ecolor=colors.get(par_version, '#444'), capsize=4, alpha=0.8)\n",
    "\n",
    "    ax.set_xlabel(\"Array Size\", fontsize=11)\n",
    "    ax.set_ylabel(\"Speedup\", fontsize=11)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([size_label(s) for s in sizes])\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(fontsize=10)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Avoid saving same path twice in one run\n",
    "    if outpath not in _saved_plot_paths:\n",
    "        fig.savefig(outpath, dpi=300, bbox_inches=\"tight\")\n",
    "        _saved_plot_paths.add(outpath)\n",
    "        print(f\"Saved: {outpath}\")\n",
    "    else:\n",
    "        print(f\"Skipped duplicate save: {outpath}\")\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "# --- Per-user plots ---\n",
    "for user in unique_users:\n",
    "    user_df = df[df[\"user\"] == user].copy()\n",
    "    if user_df.empty:\n",
    "        continue\n",
    "\n",
    "    stats = user_df.groupby([\"version\", \"size\"])[time_cols].agg([\"mean\", \"std\"]).reset_index()\n",
    "    stats.columns = [\"_\".join(c).strip(\"_\") for c in stats.columns]\n",
    "\n",
    "    # Timing plots (same as before)\n",
    "    for metric in [\"time_total\", \"time_compute\"]:\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        fig.suptitle(f\"Array Analysis — {metric.replace('time_', '').replace('_', ' ').title()} — User: {user}\", fontsize=14, fontweight=\"bold\")\n",
    "        jitter_offset = np.linspace(-0.2, 0.2, len(versions))\n",
    "\n",
    "        for idx, version in enumerate(versions):\n",
    "            version_stats = stats[stats[\"version\"] == version]\n",
    "            if version_stats.empty: continue\n",
    "            x_jitter = np.arange(len(unique_sizes)) + jitter_offset[idx]\n",
    "            y_mean = version_stats[f\"{metric}_mean\"].values\n",
    "            y_std = version_stats[f\"{metric}_std\"].values\n",
    "            ax.errorbar(x_jitter, y_mean, yerr=y_std, marker='o', label=version.replace('_', ' ').capitalize(),\n",
    "                        linewidth=2, capsize=5, linestyle='-', alpha=0.8, color=colors.get(version, \"#444\"))\n",
    "\n",
    "        ax.set_xlabel(\"Array Size\", fontsize=11)\n",
    "        ax.set_ylabel(f\"{metric.replace('time_', '').replace('_', ' ').title()} (s)\", fontsize=11)\n",
    "        ax.set_xticks(range(len(unique_sizes)))\n",
    "        ax.set_xticklabels([size_label(s) for s in unique_sizes])\n",
    "        ax.legend(fontsize=10)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        outpath = f\"plots/plot_1_3_{user}_{metric}.png\"\n",
    "        if outpath not in _saved_plot_paths:\n",
    "            fig.savefig(outpath, dpi=300, bbox_inches=\"tight\")\n",
    "            _saved_plot_paths.add(outpath)\n",
    "            print(f\"Saved: {outpath}\")\n",
    "        else:\n",
    "            print(f\"Skipped duplicate save: {outpath}\")\n",
    "        plt.close(fig)\n",
    "\n",
    "    # --- Overlay speedup plot (total) ---\n",
    "    seq_stats = stats[stats[\"version\"] == \"sequential\"]\n",
    "    common_sizes = sorted(set(seq_stats[\"size\"]) & set(stats[\"size\"]))\n",
    "    if not common_sizes: continue\n",
    "\n",
    "    seq_times = seq_stats[seq_stats[\"size\"].isin(common_sizes)].set_index(\"size\")[\"time_total_mean\"].reindex(common_sizes).values\n",
    "    seq_times_std = seq_stats[seq_stats[\"size\"].isin(common_sizes)].set_index(\"size\")[\"time_total_std\"].reindex(common_sizes).values\n",
    "\n",
    "    par_times_dict = {}\n",
    "    par_times_std_dict = {}\n",
    "    for par_version in [\"parallel_unpadded\", \"parallel_padded\", \"parallel_local_accum\"]:\n",
    "        par_times = stats[(stats[\"version\"] == par_version) & (stats[\"size\"].isin(common_sizes))]\n",
    "        par_times = par_times.set_index(\"size\")[\"time_total_mean\"].reindex(common_sizes).values\n",
    "        par_times_std = stats[(stats[\"version\"] == par_version) & (stats[\"size\"].isin(common_sizes))].set_index(\"size\")[\"time_total_std\"].reindex(common_sizes).values\n",
    "        par_times_dict[par_version] = par_times\n",
    "        par_times_std_dict[par_version] = par_times_std\n",
    "\n",
    "    plot_speedup_overlay(seq_times, par_times_dict, common_sizes,\n",
    "                         f\"Array Analysis — Total-time Speedup — User: {user}\",\n",
    "                         f\"plots/plot_1_3_{user}_speedup_overlay.png\",\n",
    "                         seq_stds=seq_times_std, par_stds_dict=par_times_std_dict)\n",
    "\n",
    "    # --- Overlay compute-time speedup for this user ---\n",
    "    seq_times_compute = seq_stats[seq_stats[\"size\"].isin(common_sizes)].set_index(\"size\")[\"time_compute_mean\"].reindex(common_sizes).values\n",
    "    seq_times_compute_std = seq_stats[seq_stats[\"size\"].isin(common_sizes)].set_index(\"size\")[\"time_compute_std\"].reindex(common_sizes).values\n",
    "    par_times_compute_dict = {}\n",
    "    par_times_compute_std_dict = {}\n",
    "    for par_version in [\"parallel_unpadded\", \"parallel_padded\", \"parallel_local_accum\"]:\n",
    "        par_times_c = stats[(stats[\"version\"] == par_version) & (stats[\"size\"].isin(common_sizes))]\n",
    "        par_times_c_mean = par_times_c.set_index(\"size\")[\"time_compute_mean\"].reindex(common_sizes).values\n",
    "        par_times_c_std = par_times_c.set_index(\"size\")[\"time_compute_std\"].reindex(common_sizes).values\n",
    "        par_times_compute_dict[par_version] = par_times_c_mean\n",
    "        par_times_compute_std_dict[par_version] = par_times_c_std\n",
    "\n",
    "    plot_speedup_overlay(seq_times_compute, par_times_compute_dict, common_sizes,\n",
    "                         f\"Array Analysis — Compute-time Speedup — User: {user}\",\n",
    "                         f\"plots/plot_1_3_{user}_compute_speedup_overlay.png\",\n",
    "                         seq_stds=seq_times_compute_std, par_stds_dict=par_times_compute_std_dict)\n",
    "\n",
    "print(\"\\nOverlay speedup plots generated for individual users (total + compute).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
