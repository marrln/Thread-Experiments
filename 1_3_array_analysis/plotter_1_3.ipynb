{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d3ac64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: plots/plot_1_3_ea24205_time_total.png\n",
      "Saved: plots/plot_1_3_ea24205_time_compute.png\n",
      "Saved: plots/plot_1_3_ea24205_speedup_overlay.png\n",
      "Saved: plots/plot_1_3_ea24205_compute_speedup_overlay.png\n",
      "Saved: plots/plot_1_3_marr_time_total.png\n",
      "Saved: plots/plot_1_3_marr_time_compute.png\n",
      "Saved: plots/plot_1_3_marr_speedup_overlay.png\n",
      "Saved: plots/plot_1_3_marr_compute_speedup_overlay.png\n",
      "Saved: plots/plot_1_3_phoebus_time_total.png\n",
      "Saved: plots/plot_1_3_phoebus_time_compute.png\n",
      "Saved: plots/plot_1_3_phoebus_speedup_overlay.png\n",
      "Saved: plots/plot_1_3_phoebus_compute_speedup_overlay.png\n",
      "Saved: plots/plot_1_3_all_users_speedup_overlay.png\n",
      "Saved: plots/plot_1_3_all_users_compute_speedup_overlay.png\n",
      "\n",
      "Overlay speedup plots generated for individual users (total + compute).\n",
      "All-users overlays generated (total + compute).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Load results CSV\n",
    "CSV_FILE = \"results_1.3.csv\"\n",
    "res_df = pd.read_csv(CSV_FILE)\n",
    "\n",
    "# Ensure plots directory exists\n",
    "os.makedirs('plots', exist_ok=True)\n",
    "\n",
    "# Normalize dataframe\n",
    "df = res_df.copy()\n",
    "df['user'] = df.get('user', 'unknown')\n",
    "df['version'] = df['version'].astype(str).str.strip().str.lower()\n",
    "df['size'] = pd.to_numeric(df.get('size'), errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "time_cols = [\"time_init\", \"time_compute\", \"time_thread_create\", \"time_thread_join\", \"time_cleanup\", \"time_total\"]\n",
    "for col in time_cols:\n",
    "    df[col] = pd.to_numeric(df.get(col), errors='coerce').fillna(0)\n",
    "\n",
    "unique_users = sorted(df[\"user\"].unique())\n",
    "unique_sizes = sorted(df[\"size\"].unique())\n",
    "versions = [\"sequential\", \"parallel_unpadded\", \"parallel_padded\", \"parallel_local_accum\"]\n",
    "colors = {\n",
    "    \"sequential\": \"#7f7f7f\",\n",
    "    \"parallel_unpadded\": \"#ff7f0e\",\n",
    "    \"parallel_padded\": \"#2ca02c\",\n",
    "    \"parallel_local_accum\": \"#d62728\"\n",
    "}\n",
    "\n",
    "# Track saved files to avoid double-saving within one run\n",
    "_saved_plot_paths = set()\n",
    "\n",
    "def size_label(n):\n",
    "    return f\"{n//1_000_000}M\" if n >= 1_000_000 else f\"{n//1000}K\" if n >= 1000 else str(n)\n",
    "\n",
    "# --- Function to overlay speedups with error propagation ---\n",
    "def plot_speedup_overlay(seq_means, par_means_dict, sizes, title, outpath, seq_stds=None, par_stds_dict=None):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    fig.suptitle(title, fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "    x = np.arange(len(sizes))\n",
    "    for par_version, par_means in par_means_dict.items():\n",
    "        # Convert to numpy arrays\n",
    "        seq = np.asarray(seq_means, dtype=float)\n",
    "        par = np.asarray(par_means, dtype=float)\n",
    "\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            speedup = np.where(par > 0, seq / par, np.nan)\n",
    "\n",
    "        # Error propagation for S = A / B: var(S) ≈ S^2 * ( (σ_A/μ_A)^2 + (σ_B/μ_B)^2 )\n",
    "        speedup_err = np.full_like(speedup, np.nan)\n",
    "        if seq_stds is not None and par_stds_dict is not None and par_version in par_stds_dict:\n",
    "            seq_s = np.asarray(seq_stds, dtype=float)\n",
    "            par_s = np.asarray(par_stds_dict[par_version], dtype=float)\n",
    "            # Avoid division by zero; only compute where means > 0\n",
    "            valid = (seq > 0) & (par > 0)\n",
    "            rel_sq = np.zeros_like(speedup)\n",
    "            # compute relative squared errors safely\n",
    "            rel_sq[valid] = (seq_s[valid] / seq[valid]) ** 2 + (par_s[valid] / par[valid]) ** 2\n",
    "            speedup_err[valid] = np.abs(speedup[valid]) * np.sqrt(rel_sq[valid])\n",
    "\n",
    "        # Plot mean\n",
    "        ax.plot(x, speedup, marker='o', linewidth=2, markersize=8,\n",
    "                label=par_version.replace('_', ' ').capitalize(), color=colors.get(par_version, '#444'))\n",
    "\n",
    "        # Plot error band if available\n",
    "        if np.any(np.isfinite(speedup_err)):\n",
    "            lower = speedup - speedup_err\n",
    "            upper = speedup + speedup_err\n",
    "            ax.fill_between(x, lower, upper, alpha=0.2, color=colors.get(par_version, '#444'))\n",
    "            # also show small errorbars on markers\n",
    "            ax.errorbar(x, speedup, yerr=speedup_err, fmt='none', ecolor=colors.get(par_version, '#444'), capsize=4, alpha=0.8)\n",
    "\n",
    "    ax.set_xlabel(\"Array Size\", fontsize=11)\n",
    "    ax.set_ylabel(\"Speedup\", fontsize=11)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([size_label(s) for s in sizes])\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(fontsize=10)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Avoid saving same path twice in one run\n",
    "    if outpath not in _saved_plot_paths:\n",
    "        fig.savefig(outpath, dpi=300, bbox_inches=\"tight\")\n",
    "        _saved_plot_paths.add(outpath)\n",
    "        print(f\"Saved: {outpath}\")\n",
    "    else:\n",
    "        print(f\"Skipped duplicate save: {outpath}\")\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "# --- Per-user plots ---\n",
    "for user in unique_users:\n",
    "    user_df = df[df[\"user\"] == user].copy()\n",
    "    if user_df.empty:\n",
    "        continue\n",
    "\n",
    "    stats = user_df.groupby([\"version\", \"size\"])[time_cols].agg([\"mean\", \"std\"]).reset_index()\n",
    "    stats.columns = [\"_\".join(c).strip(\"_\") for c in stats.columns]\n",
    "\n",
    "    # Timing plots (same as before)\n",
    "    for metric in [\"time_total\", \"time_compute\"]:\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        fig.suptitle(f\"Array Analysis — {metric.replace('time_', '').replace('_', ' ').title()} — User: {user}\", fontsize=14, fontweight=\"bold\")\n",
    "        jitter_offset = np.linspace(-0.2, 0.2, len(versions))\n",
    "\n",
    "        for idx, version in enumerate(versions):\n",
    "            version_stats = stats[stats[\"version\"] == version]\n",
    "            if version_stats.empty: continue\n",
    "            x_jitter = np.arange(len(unique_sizes)) + jitter_offset[idx]\n",
    "            y_mean = version_stats[f\"{metric}_mean\"].values\n",
    "            y_std = version_stats[f\"{metric}_std\"].values\n",
    "            ax.errorbar(x_jitter, y_mean, yerr=y_std, marker='o', label=version.replace('_', ' ').capitalize(),\n",
    "                        linewidth=2, capsize=5, linestyle='-', alpha=0.8, color=colors.get(version, \"#444\"))\n",
    "\n",
    "        ax.set_xlabel(\"Array Size\", fontsize=11)\n",
    "        ax.set_ylabel(f\"{metric.replace('time_', '').replace('_', ' ').title()} (s)\", fontsize=11)\n",
    "        ax.set_xticks(range(len(unique_sizes)))\n",
    "        ax.set_xticklabels([size_label(s) for s in unique_sizes])\n",
    "        ax.legend(fontsize=10)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        outpath = f\"plots/plot_1_3_{user}_{metric}.png\"\n",
    "        if outpath not in _saved_plot_paths:\n",
    "            fig.savefig(outpath, dpi=300, bbox_inches=\"tight\")\n",
    "            _saved_plot_paths.add(outpath)\n",
    "            print(f\"Saved: {outpath}\")\n",
    "        else:\n",
    "            print(f\"Skipped duplicate save: {outpath}\")\n",
    "        plt.close(fig)\n",
    "\n",
    "    # --- Overlay speedup plot (total) ---\n",
    "    seq_stats = stats[stats[\"version\"] == \"sequential\"]\n",
    "    common_sizes = sorted(set(seq_stats[\"size\"]) & set(stats[\"size\"]))\n",
    "    if not common_sizes: continue\n",
    "\n",
    "    seq_times = seq_stats[seq_stats[\"size\"].isin(common_sizes)].set_index(\"size\")[\"time_total_mean\"].reindex(common_sizes).values\n",
    "    seq_times_std = seq_stats[seq_stats[\"size\"].isin(common_sizes)].set_index(\"size\")[\"time_total_std\"].reindex(common_sizes).values\n",
    "\n",
    "    par_times_dict = {}\n",
    "    par_times_std_dict = {}\n",
    "    for par_version in [\"parallel_unpadded\", \"parallel_padded\", \"parallel_local_accum\"]:\n",
    "        par_times = stats[(stats[\"version\"] == par_version) & (stats[\"size\"].isin(common_sizes))]\n",
    "        par_times = par_times.set_index(\"size\")[\"time_total_mean\"].reindex(common_sizes).values\n",
    "        par_times_std = stats[(stats[\"version\"] == par_version) & (stats[\"size\"].isin(common_sizes))].set_index(\"size\")[\"time_total_std\"].reindex(common_sizes).values\n",
    "        par_times_dict[par_version] = par_times\n",
    "        par_times_std_dict[par_version] = par_times_std\n",
    "\n",
    "    plot_speedup_overlay(seq_times, par_times_dict, common_sizes,\n",
    "                         f\"Array Analysis — Total-time Speedup — User: {user}\",\n",
    "                         f\"plots/plot_1_3_{user}_speedup_overlay.png\",\n",
    "                         seq_stds=seq_times_std, par_stds_dict=par_times_std_dict)\n",
    "\n",
    "    # --- Overlay compute-time speedup for this user ---\n",
    "    seq_times_compute = seq_stats[seq_stats[\"size\"].isin(common_sizes)].set_index(\"size\")[\"time_compute_mean\"].reindex(common_sizes).values\n",
    "    seq_times_compute_std = seq_stats[seq_stats[\"size\"].isin(common_sizes)].set_index(\"size\")[\"time_compute_std\"].reindex(common_sizes).values\n",
    "    par_times_compute_dict = {}\n",
    "    par_times_compute_std_dict = {}\n",
    "    for par_version in [\"parallel_unpadded\", \"parallel_padded\", \"parallel_local_accum\"]:\n",
    "        par_times_c = stats[(stats[\"version\"] == par_version) & (stats[\"size\"].isin(common_sizes))]\n",
    "        par_times_c_mean = par_times_c.set_index(\"size\")[\"time_compute_mean\"].reindex(common_sizes).values\n",
    "        par_times_c_std = par_times_c.set_index(\"size\")[\"time_compute_std\"].reindex(common_sizes).values\n",
    "        par_times_compute_dict[par_version] = par_times_c_mean\n",
    "        par_times_compute_std_dict[par_version] = par_times_c_std\n",
    "\n",
    "    plot_speedup_overlay(seq_times_compute, par_times_compute_dict, common_sizes,\n",
    "                         f\"Array Analysis — Compute-time Speedup — User: {user}\",\n",
    "                         f\"plots/plot_1_3_{user}_compute_speedup_overlay.png\",\n",
    "                         seq_stds=seq_times_compute_std, par_stds_dict=par_times_compute_std_dict)\n",
    "\n",
    "# --- All-users combined overlay speedup ---\n",
    "if len(unique_users) > 1:\n",
    "    stats_all = df.groupby([\"version\", \"size\"])[time_cols].agg([\"mean\", \"std\"]).reset_index()\n",
    "    stats_all.columns = [\"_\".join(c).strip(\"_\") for c in stats_all.columns]\n",
    "\n",
    "    common_sizes = sorted(set(stats_all[stats_all[\"version\"] == \"sequential\"][\"size\"]) &\n",
    "                          set(stats_all[\"size\"]))\n",
    "    seq_times_all = stats_all[(stats_all[\"version\"] == \"sequential\") & (stats_all[\"size\"].isin(common_sizes))]\n",
    "    seq_times_all_mean = seq_times_all.set_index(\"size\")[\"time_total_mean\"].reindex(common_sizes).values\n",
    "    seq_times_all_std = seq_times_all.set_index(\"size\")[\"time_total_std\"].reindex(common_sizes).values\n",
    "\n",
    "    par_times_dict_all = {}\n",
    "    par_times_dict_all_std = {}\n",
    "    for par_version in [\"parallel_unpadded\", \"parallel_padded\", \"parallel_local_accum\"]:\n",
    "        par_times = stats_all[(stats_all[\"version\"] == par_version) & (stats_all[\"size\"].isin(common_sizes))]\n",
    "        par_times_mean = par_times.set_index(\"size\")[\"time_total_mean\"].reindex(common_sizes).values\n",
    "        par_times_std = par_times.set_index(\"size\")[\"time_total_std\"].reindex(common_sizes).values\n",
    "        par_times_dict_all[par_version] = par_times_mean\n",
    "        par_times_dict_all_std[par_version] = par_times_std\n",
    "\n",
    "    plot_speedup_overlay(seq_times_all_mean, par_times_dict_all, common_sizes,\n",
    "                         \"Array Analysis — Total-time Speedup — All Users\",\n",
    "                         \"plots/plot_1_3_all_users_speedup_overlay.png\",\n",
    "                         seq_stds=seq_times_all_std, par_stds_dict=par_times_dict_all_std)\n",
    "\n",
    "    # --- All-users compute-time overlay speedup ---\n",
    "    seq_times_all_compute = stats_all[(stats_all[\"version\"] == \"sequential\") & (stats_all[\"size\"].isin(common_sizes))]\n",
    "    seq_times_all_compute_mean = seq_times_all_compute.set_index(\"size\")[\"time_compute_mean\"].reindex(common_sizes).values\n",
    "    seq_times_all_compute_std = seq_times_all_compute.set_index(\"size\")[\"time_compute_std\"].reindex(common_sizes).values\n",
    "\n",
    "    par_times_dict_all_compute = {}\n",
    "    par_times_dict_all_compute_std = {}\n",
    "    for par_version in [\"parallel_unpadded\", \"parallel_padded\", \"parallel_local_accum\"]:\n",
    "        par_times_c = stats_all[(stats_all[\"version\"] == par_version) & (stats_all[\"size\"].isin(common_sizes))]\n",
    "        par_times_c_mean = par_times_c.set_index(\"size\")[\"time_compute_mean\"].reindex(common_sizes).values\n",
    "        par_times_c_std = par_times_c.set_index(\"size\")[\"time_compute_std\"].reindex(common_sizes).values\n",
    "        par_times_dict_all_compute[par_version] = par_times_c_mean\n",
    "        par_times_dict_all_compute_std[par_version] = par_times_c_std\n",
    "\n",
    "    plot_speedup_overlay(seq_times_all_compute_mean, par_times_dict_all_compute, common_sizes,\n",
    "                         \"Array Analysis — Compute-time Speedup — All Users\",\n",
    "                         \"plots/plot_1_3_all_users_compute_speedup_overlay.png\",\n",
    "                         seq_stds=seq_times_all_compute_std, par_stds_dict=par_times_dict_all_compute_std)\n",
    "else:\n",
    "    print(f\"Skipping all-users overlay generation: only {len(unique_users)} user(s) present.\")\n",
    "\n",
    "print(\"\\nOverlay speedup plots generated for individual users (total + compute).\")\n",
    "if len(unique_users) > 1:\n",
    "    print(\"All-users overlays generated (total + compute).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b820a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrlnp\\AppData\\Local\\Temp\\ipykernel_20276\\2838813720.py:7: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  seq_total_mean = float(seq_row['time_total_mean']) if not seq_row.empty else np.nan\n",
      "C:\\Users\\mrlnp\\AppData\\Local\\Temp\\ipykernel_20276\\2838813720.py:8: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  seq_total_std = float(seq_row['time_total_std']) if not seq_row.empty else np.nan\n",
      "C:\\Users\\mrlnp\\AppData\\Local\\Temp\\ipykernel_20276\\2838813720.py:9: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  seq_compute_mean = float(seq_row['time_compute_mean']) if not seq_row.empty else np.nan\n",
      "C:\\Users\\mrlnp\\AppData\\Local\\Temp\\ipykernel_20276\\2838813720.py:10: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  seq_compute_std = float(seq_row['time_compute_std']) if not seq_row.empty else np.nan\n",
      "C:\\Users\\mrlnp\\AppData\\Local\\Temp\\ipykernel_20276\\2838813720.py:16: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  total_mean = float(r['time_total_mean'])\n",
      "C:\\Users\\mrlnp\\AppData\\Local\\Temp\\ipykernel_20276\\2838813720.py:17: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  total_std = float(r['time_total_std'])\n",
      "C:\\Users\\mrlnp\\AppData\\Local\\Temp\\ipykernel_20276\\2838813720.py:18: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  compute_mean = float(r['time_compute_mean'])\n",
      "C:\\Users\\mrlnp\\AppData\\Local\\Temp\\ipykernel_20276\\2838813720.py:19: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  compute_std = float(r['time_compute_std'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>version</th>\n",
       "      <th>time_total_mean_ms</th>\n",
       "      <th>time_total_std_ms</th>\n",
       "      <th>time_compute_mean_ms</th>\n",
       "      <th>time_compute_std_ms</th>\n",
       "      <th>speedup_total_percentage</th>\n",
       "      <th>speedup_total_std_percentage</th>\n",
       "      <th>speedup_compute_percentage</th>\n",
       "      <th>speedup_compute_std_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>parallel_local_accum</td>\n",
       "      <td>2.9989</td>\n",
       "      <td>2.1132</td>\n",
       "      <td>0.7913</td>\n",
       "      <td>1.0692</td>\n",
       "      <td>65.8723</td>\n",
       "      <td>69.7568</td>\n",
       "      <td>33.7097</td>\n",
       "      <td>52.3352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100000</td>\n",
       "      <td>parallel_padded</td>\n",
       "      <td>4.4624</td>\n",
       "      <td>5.5983</td>\n",
       "      <td>2.0084</td>\n",
       "      <td>4.4614</td>\n",
       "      <td>44.2692</td>\n",
       "      <td>65.6432</td>\n",
       "      <td>13.2809</td>\n",
       "      <td>31.1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100000</td>\n",
       "      <td>parallel_unpadded</td>\n",
       "      <td>2.8910</td>\n",
       "      <td>1.9738</td>\n",
       "      <td>0.8397</td>\n",
       "      <td>0.3434</td>\n",
       "      <td>68.3316</td>\n",
       "      <td>71.3735</td>\n",
       "      <td>31.7641</td>\n",
       "      <td>27.5407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100000</td>\n",
       "      <td>sequential</td>\n",
       "      <td>1.9755</td>\n",
       "      <td>1.5616</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.2039</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>111.7925</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>108.1205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000000</td>\n",
       "      <td>parallel_local_accum</td>\n",
       "      <td>15.7096</td>\n",
       "      <td>6.8587</td>\n",
       "      <td>1.9596</td>\n",
       "      <td>2.2392</td>\n",
       "      <td>132.3199</td>\n",
       "      <td>101.8650</td>\n",
       "      <td>121.0859</td>\n",
       "      <td>148.5400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000000</td>\n",
       "      <td>parallel_padded</td>\n",
       "      <td>14.3541</td>\n",
       "      <td>5.0727</td>\n",
       "      <td>2.3433</td>\n",
       "      <td>1.1492</td>\n",
       "      <td>144.8156</td>\n",
       "      <td>105.1217</td>\n",
       "      <td>101.2575</td>\n",
       "      <td>67.1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000000</td>\n",
       "      <td>parallel_unpadded</td>\n",
       "      <td>15.8176</td>\n",
       "      <td>5.2290</td>\n",
       "      <td>3.3926</td>\n",
       "      <td>1.6029</td>\n",
       "      <td>131.4165</td>\n",
       "      <td>93.9719</td>\n",
       "      <td>69.9405</td>\n",
       "      <td>45.4563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000000</td>\n",
       "      <td>sequential</td>\n",
       "      <td>20.7869</td>\n",
       "      <td>13.1803</td>\n",
       "      <td>2.3728</td>\n",
       "      <td>1.0590</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>89.6704</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>63.1146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10000000</td>\n",
       "      <td>parallel_local_accum</td>\n",
       "      <td>112.1216</td>\n",
       "      <td>33.1869</td>\n",
       "      <td>10.0577</td>\n",
       "      <td>2.3985</td>\n",
       "      <td>99.8019</td>\n",
       "      <td>35.3239</td>\n",
       "      <td>175.8806</td>\n",
       "      <td>48.6902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10000000</td>\n",
       "      <td>parallel_padded</td>\n",
       "      <td>120.3936</td>\n",
       "      <td>33.8302</td>\n",
       "      <td>21.8084</td>\n",
       "      <td>9.2001</td>\n",
       "      <td>92.9447</td>\n",
       "      <td>31.7406</td>\n",
       "      <td>81.1137</td>\n",
       "      <td>36.0692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10000000</td>\n",
       "      <td>parallel_unpadded</td>\n",
       "      <td>124.4943</td>\n",
       "      <td>36.1582</td>\n",
       "      <td>26.6049</td>\n",
       "      <td>12.3745</td>\n",
       "      <td>89.8832</td>\n",
       "      <td>31.3973</td>\n",
       "      <td>66.4899</td>\n",
       "      <td>32.3081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10000000</td>\n",
       "      <td>sequential</td>\n",
       "      <td>111.8995</td>\n",
       "      <td>21.7164</td>\n",
       "      <td>17.6896</td>\n",
       "      <td>2.4872</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>27.4457</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>19.8845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50000000</td>\n",
       "      <td>parallel_local_accum</td>\n",
       "      <td>525.6975</td>\n",
       "      <td>122.7568</td>\n",
       "      <td>35.8768</td>\n",
       "      <td>6.6664</td>\n",
       "      <td>108.4556</td>\n",
       "      <td>34.8158</td>\n",
       "      <td>247.5236</td>\n",
       "      <td>59.1301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50000000</td>\n",
       "      <td>parallel_padded</td>\n",
       "      <td>587.5699</td>\n",
       "      <td>156.3294</td>\n",
       "      <td>92.9280</td>\n",
       "      <td>40.2733</td>\n",
       "      <td>97.0350</td>\n",
       "      <td>33.5172</td>\n",
       "      <td>95.5617</td>\n",
       "      <td>43.8294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50000000</td>\n",
       "      <td>parallel_unpadded</td>\n",
       "      <td>611.2565</td>\n",
       "      <td>162.7440</td>\n",
       "      <td>119.5559</td>\n",
       "      <td>51.7373</td>\n",
       "      <td>93.2748</td>\n",
       "      <td>32.2316</td>\n",
       "      <td>74.2778</td>\n",
       "      <td>34.0229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50000000</td>\n",
       "      <td>sequential</td>\n",
       "      <td>570.1481</td>\n",
       "      <td>125.5910</td>\n",
       "      <td>88.8035</td>\n",
       "      <td>13.3324</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>31.1520</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>21.2321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100000000</td>\n",
       "      <td>parallel_local_accum</td>\n",
       "      <td>1032.3525</td>\n",
       "      <td>260.2118</td>\n",
       "      <td>70.2575</td>\n",
       "      <td>13.2513</td>\n",
       "      <td>111.2701</td>\n",
       "      <td>38.4518</td>\n",
       "      <td>252.1948</td>\n",
       "      <td>60.8099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100000000</td>\n",
       "      <td>parallel_padded</td>\n",
       "      <td>1167.6161</td>\n",
       "      <td>311.0743</td>\n",
       "      <td>189.2959</td>\n",
       "      <td>82.8945</td>\n",
       "      <td>98.3799</td>\n",
       "      <td>35.0412</td>\n",
       "      <td>93.6025</td>\n",
       "      <td>43.3341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100000000</td>\n",
       "      <td>parallel_unpadded</td>\n",
       "      <td>1204.6432</td>\n",
       "      <td>351.5110</td>\n",
       "      <td>230.1449</td>\n",
       "      <td>114.0575</td>\n",
       "      <td>95.3560</td>\n",
       "      <td>35.8103</td>\n",
       "      <td>76.9887</td>\n",
       "      <td>39.8691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100000000</td>\n",
       "      <td>sequential</td>\n",
       "      <td>1148.6999</td>\n",
       "      <td>271.5575</td>\n",
       "      <td>177.1857</td>\n",
       "      <td>26.6168</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>33.4326</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>21.2443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         size               version  time_total_mean_ms  time_total_std_ms  \\\n",
       "0      100000  parallel_local_accum              2.9989             2.1132   \n",
       "1      100000       parallel_padded              4.4624             5.5983   \n",
       "2      100000     parallel_unpadded              2.8910             1.9738   \n",
       "3      100000            sequential              1.9755             1.5616   \n",
       "4     1000000  parallel_local_accum             15.7096             6.8587   \n",
       "5     1000000       parallel_padded             14.3541             5.0727   \n",
       "6     1000000     parallel_unpadded             15.8176             5.2290   \n",
       "7     1000000            sequential             20.7869            13.1803   \n",
       "8    10000000  parallel_local_accum            112.1216            33.1869   \n",
       "9    10000000       parallel_padded            120.3936            33.8302   \n",
       "10   10000000     parallel_unpadded            124.4943            36.1582   \n",
       "11   10000000            sequential            111.8995            21.7164   \n",
       "12   50000000  parallel_local_accum            525.6975           122.7568   \n",
       "13   50000000       parallel_padded            587.5699           156.3294   \n",
       "14   50000000     parallel_unpadded            611.2565           162.7440   \n",
       "15   50000000            sequential            570.1481           125.5910   \n",
       "16  100000000  parallel_local_accum           1032.3525           260.2118   \n",
       "17  100000000       parallel_padded           1167.6161           311.0743   \n",
       "18  100000000     parallel_unpadded           1204.6432           351.5110   \n",
       "19  100000000            sequential           1148.6999           271.5575   \n",
       "\n",
       "    time_compute_mean_ms  time_compute_std_ms  speedup_total_percentage  \\\n",
       "0                 0.7913               1.0692                   65.8723   \n",
       "1                 2.0084               4.4614                   44.2692   \n",
       "2                 0.8397               0.3434                   68.3316   \n",
       "3                 0.2667               0.2039                  100.0000   \n",
       "4                 1.9596               2.2392                  132.3199   \n",
       "5                 2.3433               1.1492                  144.8156   \n",
       "6                 3.3926               1.6029                  131.4165   \n",
       "7                 2.3728               1.0590                  100.0000   \n",
       "8                10.0577               2.3985                   99.8019   \n",
       "9                21.8084               9.2001                   92.9447   \n",
       "10               26.6049              12.3745                   89.8832   \n",
       "11               17.6896               2.4872                  100.0000   \n",
       "12               35.8768               6.6664                  108.4556   \n",
       "13               92.9280              40.2733                   97.0350   \n",
       "14              119.5559              51.7373                   93.2748   \n",
       "15               88.8035              13.3324                  100.0000   \n",
       "16               70.2575              13.2513                  111.2701   \n",
       "17              189.2959              82.8945                   98.3799   \n",
       "18              230.1449             114.0575                   95.3560   \n",
       "19              177.1857              26.6168                  100.0000   \n",
       "\n",
       "    speedup_total_std_percentage  speedup_compute_percentage  \\\n",
       "0                        69.7568                     33.7097   \n",
       "1                        65.6432                     13.2809   \n",
       "2                        71.3735                     31.7641   \n",
       "3                       111.7925                    100.0000   \n",
       "4                       101.8650                    121.0859   \n",
       "5                       105.1217                    101.2575   \n",
       "6                        93.9719                     69.9405   \n",
       "7                        89.6704                    100.0000   \n",
       "8                        35.3239                    175.8806   \n",
       "9                        31.7406                     81.1137   \n",
       "10                       31.3973                     66.4899   \n",
       "11                       27.4457                    100.0000   \n",
       "12                       34.8158                    247.5236   \n",
       "13                       33.5172                     95.5617   \n",
       "14                       32.2316                     74.2778   \n",
       "15                       31.1520                    100.0000   \n",
       "16                       38.4518                    252.1948   \n",
       "17                       35.0412                     93.6025   \n",
       "18                       35.8103                     76.9887   \n",
       "19                       33.4326                    100.0000   \n",
       "\n",
       "    speedup_compute_std_percentage  \n",
       "0                          52.3352  \n",
       "1                          31.1999  \n",
       "2                          27.5407  \n",
       "3                         108.1205  \n",
       "4                         148.5400  \n",
       "5                          67.1410  \n",
       "6                          45.4563  \n",
       "7                          63.1146  \n",
       "8                          48.6902  \n",
       "9                          36.0692  \n",
       "10                         32.3081  \n",
       "11                         19.8845  \n",
       "12                         59.1301  \n",
       "13                         43.8294  \n",
       "14                         34.0229  \n",
       "15                         21.2321  \n",
       "16                         60.8099  \n",
       "17                         43.3341  \n",
       "18                         39.8691  \n",
       "19                         21.2443  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build a concise summary table per size/version with speedups (and propagated std)\n",
    "src = stats_all if 'stats_all' in globals() and isinstance(stats_all, pd.DataFrame) and not stats_all.empty else stats\n",
    "\n",
    "rows = []\n",
    "for s in sorted(src['size'].unique()):\n",
    "    seq_row = src[(src['version'] == 'sequential') & (src['size'] == s)]\n",
    "    seq_total_mean = float(seq_row['time_total_mean']) if not seq_row.empty else np.nan\n",
    "    seq_total_std = float(seq_row['time_total_std']) if not seq_row.empty else np.nan\n",
    "    seq_compute_mean = float(seq_row['time_compute_mean']) if not seq_row.empty else np.nan\n",
    "    seq_compute_std = float(seq_row['time_compute_std']) if not seq_row.empty else np.nan\n",
    "\n",
    "    for v in sorted(src['version'].unique()):\n",
    "        r = src[(src['version'] == v) & (src['size'] == s)]\n",
    "        if r.empty:\n",
    "            continue\n",
    "        total_mean = float(r['time_total_mean'])\n",
    "        total_std = float(r['time_total_std'])\n",
    "        compute_mean = float(r['time_compute_mean'])\n",
    "        compute_std = float(r['time_compute_std'])\n",
    "\n",
    "        # speedup = sequential / current\n",
    "        def compute_speedup(mu_a, sigma_a, mu_b, sigma_b):\n",
    "            if mu_a > 0 and mu_b > 0:\n",
    "                s = mu_a / mu_b\n",
    "                rel_sq = (sigma_a / mu_a) ** 2 + (sigma_b / mu_b) ** 2\n",
    "                s_std = abs(s) * np.sqrt(rel_sq)\n",
    "                return s, s_std\n",
    "            return np.nan, np.nan\n",
    "\n",
    "        speedup_total_mean, speedup_total_std = compute_speedup(seq_total_mean, seq_total_std, total_mean, total_std)\n",
    "        speedup_compute_mean, speedup_compute_std = compute_speedup(seq_compute_mean, seq_compute_std, compute_mean, compute_std)\n",
    "\n",
    "        rows.append({\n",
    "            'size': s,\n",
    "            'version': v,\n",
    "            'time_total_mean_ms': total_mean * 1000,\n",
    "            'time_total_std_ms': total_std * 1000,\n",
    "            'time_compute_mean_ms': compute_mean * 1000,\n",
    "            'time_compute_std_ms': compute_std * 1000,\n",
    "            'speedup_total_percentage': speedup_total_mean * 100,\n",
    "            'speedup_total_std_percentage': speedup_total_std * 100,\n",
    "            'speedup_compute_percentage': speedup_compute_mean * 100,\n",
    "            'speedup_compute_std_percentage': speedup_compute_std * 100\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(rows).sort_values(['size', 'version']).reset_index(drop=True)\n",
    "\n",
    "# nicer formatting for display in Jupyter\n",
    "pd.set_option('display.precision', 4)\n",
    "display(summary_df)\n",
    "\n",
    "# # save CSV for later reference\n",
    "# out_csv = \"plots/summary_table.csv\"\n",
    "# summary_df.to_csv(out_csv, index=False)\n",
    "# print(f\"Saved summary to: {out_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
