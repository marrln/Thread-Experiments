{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085106db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "CSV_PATH = os.path.join(os.getcwd(), 'results_3.2.csv')\n",
    "PLOTS_DIR = os.path.join(os.getcwd(), 'plots')\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "res = pd.read_csv(CSV_PATH)\n",
    "if 'user' not in res.columns:\n",
    "    res['user'] = 'unknown'\n",
    "\n",
    "res['n'] = res['n'].astype(int)\n",
    "res['sparsity'] = res['sparsity'].astype(int)\n",
    "res['reps'] = res['reps'].astype(int)\n",
    "res['procs_label'] = res['procs'].astype(str)\n",
    "\n",
    "def procs_to_int(x):\n",
    "    if str(x).lower() == 'sequential':\n",
    "        return -1\n",
    "    try:\n",
    "        return int(x)\n",
    "    except Exception:\n",
    "        return 1\n",
    "\n",
    "res['procs'] = res['procs_label'].apply(procs_to_int)\n",
    "\n",
    "# Component labels for timing breakdown\n",
    "component_labels = {\n",
    "    'time_csr_construct': 'CSR Construct',\n",
    "    'time_send': 'MPI Send',\n",
    "    'time_spmv': 'CSR SpMV',\n",
    "    'time_dense_total': 'Dense'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f38d91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSR (stacked) vs Dense comparison\n",
    "def plot_csr_vs_dense_subplots(df, user):\n",
    "    user_data = df[df['user'] == user].copy()\n",
    "    if user_data.empty:\n",
    "        return\n",
    "    \n",
    "    # Get unique n values and sparsity levels\n",
    "    n_values = sorted(user_data['n'].unique())\n",
    "    sparsity_values = sorted(user_data['sparsity'].unique())\n",
    "    \n",
    "    if len(n_values) == 0 or len(sparsity_values) == 0:\n",
    "        return\n",
    "    \n",
    "    # Patterns for different n values\n",
    "    n_patterns = {}\n",
    "    patterns_list = ['', '..', '//', 'xx', '\\\\\\\\', '||', '--', '++', 'oo', '**']\n",
    "    for i, n in enumerate(n_values):\n",
    "        n_patterns[n] = patterns_list[i % len(patterns_list)]\n",
    "    \n",
    "    # Create subplots (2x2 grid) - one for each sparsity\n",
    "    nplots = min(len(sparsity_values), 4)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx in range(nplots):\n",
    "        sparsity = sparsity_values[idx]\n",
    "        \n",
    "        data = user_data[user_data['sparsity'] == sparsity].copy()\n",
    "        if data.empty:\n",
    "            continue\n",
    "        \n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Get unique process counts\n",
    "        procs_values = sorted(data['procs'].unique())\n",
    "        x_positions = np.arange(len(procs_values))\n",
    "        \n",
    "        # Calculate bar width based on number of n values\n",
    "        num_bars = len(n_values) * 2  # CSR and Dense for each n\n",
    "        bar_width = 0.8 / num_bars if num_bars > 0 else 0.8\n",
    "        \n",
    "        bar_idx = 0\n",
    "        for n in n_values:\n",
    "            n_data = data[data['n'] == n].copy()\n",
    "            if n_data.empty:\n",
    "                bar_idx += 2\n",
    "                continue\n",
    "            \n",
    "            summary_mean = n_data.groupby('procs').mean(numeric_only=True).reset_index()\n",
    "            summary_std = n_data.groupby('procs').std(numeric_only=True).reset_index().fillna(0)\n",
    "            summary_mean = summary_mean.sort_values('procs')\n",
    "            summary_std = summary_std.set_index('procs').reindex(summary_mean['procs']).reset_index(drop=True)\n",
    "            \n",
    "            # Ensure we have data for all process values\n",
    "            procs_data = summary_mean['procs'].values\n",
    "            if len(procs_data) == 0:\n",
    "                bar_idx += 2\n",
    "                continue\n",
    "            \n",
    "            # Get CSR components (including time_send for MPI overhead)\n",
    "            csr_construct_mean = summary_mean['time_csr_construct'].values\n",
    "            csr_send_mean = summary_mean['time_send'].values\n",
    "            csr_spmv_mean = summary_mean['time_spmv'].values\n",
    "            csr_construct_std = summary_std['time_csr_construct'].values\n",
    "            csr_send_std = summary_std['time_send'].values\n",
    "            csr_spmv_std = summary_std['time_spmv'].values\n",
    "            \n",
    "            # Calculate total CSR error (error propagation for sum of 3 components)\n",
    "            csr_total_mean = csr_construct_mean + csr_send_mean + csr_spmv_mean\n",
    "            csr_total_std = np.sqrt(csr_construct_std**2 + csr_send_std**2 + csr_spmv_std**2)\n",
    "            csr_total_std = np.minimum(csr_total_std, csr_total_mean)\n",
    "            \n",
    "            # Get Dense\n",
    "            dense_mean = summary_mean['time_dense_total'].values\n",
    "            dense_std = np.minimum(summary_std['time_dense_total'].values, dense_mean)\n",
    "            \n",
    "            # Calculate offsets for this n\n",
    "            offset_csr = bar_idx * bar_width - 0.4 + bar_width/2\n",
    "            offset_dense = (bar_idx + 1) * bar_width - 0.4 + bar_width/2\n",
    "            \n",
    "            # Map processes to x positions\n",
    "            x_pos = []\n",
    "            for p in procs_data:\n",
    "                if p in procs_values:\n",
    "                    x_pos.append(procs_values.index(p))\n",
    "            x_pos = np.array(x_pos)\n",
    "            \n",
    "            # CSR bar (stacked) - bottom without error bar\n",
    "            ax.bar(x_pos + offset_csr, csr_construct_mean, bar_width, \n",
    "                   label=f'CSR Construct (n={n})' if bar_idx == 0 else None,\n",
    "                   color='#4C72B0', alpha=0.85, edgecolor='black', linewidth=0.5,\n",
    "                   hatch=n_patterns[n])\n",
    "            \n",
    "            # CSR bar (stacked) - middle layer (MPI Send)\n",
    "            ax.bar(x_pos + offset_csr, csr_send_mean, bar_width, \n",
    "                   bottom=csr_construct_mean,\n",
    "                   label=f'MPI Send (n={n})' if bar_idx == 0 else None,\n",
    "                   color='#DD8452', alpha=0.85, edgecolor='black', linewidth=0.5,\n",
    "                   hatch=n_patterns[n])\n",
    "            \n",
    "            # CSR bar (stacked) - top with total error bar\n",
    "            ax.bar(x_pos + offset_csr, csr_spmv_mean, bar_width, \n",
    "                   bottom=csr_construct_mean + csr_send_mean,\n",
    "                   yerr=csr_total_std, capsize=3,\n",
    "                   label=f'CSR SpMV (n={n})' if bar_idx == 0 else None,\n",
    "                   color='#55A868', alpha=0.85, edgecolor='black', linewidth=0.5,\n",
    "                   hatch=n_patterns[n])\n",
    "            \n",
    "            # Dense bar\n",
    "            ax.bar(x_pos + offset_dense, dense_mean, bar_width, \n",
    "                   yerr=dense_std, capsize=3,\n",
    "                   label=f'Dense (n={n})' if bar_idx == 0 else None,\n",
    "                   color='#C44E52', alpha=0.85, edgecolor='black', linewidth=0.5,\n",
    "                   hatch=n_patterns[n])\n",
    "            \n",
    "            bar_idx += 2\n",
    "        \n",
    "        ax.set_xticks(x_positions)\n",
    "        ax.set_xticklabels([str(int(p)) if p != -1 else 'seq' for p in procs_values])\n",
    "        ax.set_xlabel('Processes')\n",
    "        ax.set_ylabel('Time (s)')\n",
    "        ax.set_yscale('log')\n",
    "        ax.set_title(f'Sparsity = {sparsity}%')\n",
    "        ax.grid(axis='y', alpha=0.25)\n",
    "        if idx == 0:\n",
    "            # Create legend with colors and patterns\n",
    "            from matplotlib.patches import Patch\n",
    "            handles = []\n",
    "            labels = []\n",
    "            \n",
    "            # First add color legend (components)\n",
    "            handles.append(Patch(facecolor='#4C72B0', edgecolor='black', alpha=0.85))\n",
    "            labels.append('CSR Construct')\n",
    "            handles.append(Patch(facecolor='#DD8452', edgecolor='black', alpha=0.85))\n",
    "            labels.append('MPI Send')\n",
    "            handles.append(Patch(facecolor='#55A868', edgecolor='black', alpha=0.85))\n",
    "            labels.append('CSR SpMV')\n",
    "            handles.append(Patch(facecolor='#C44E52', edgecolor='black', alpha=0.85))\n",
    "            labels.append('Dense')\n",
    "            \n",
    "            # Add separator\n",
    "            handles.append(Patch(facecolor='white', edgecolor='white'))\n",
    "            labels.append('')\n",
    "            \n",
    "            # Then add pattern legend (n values)\n",
    "            for n in n_values:\n",
    "                handles.append(Patch(facecolor='lightgray', edgecolor='black', hatch=n_patterns[n]))\n",
    "                labels.append(f'n={n}')\n",
    "            \n",
    "            ax.legend(handles, labels, fontsize=8, loc='upper right', ncol=1)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(nplots, 4):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    fig.suptitle(f'CSR Total vs Dense for Different Matrix Sizes (User: {user})', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fname = os.path.join(PLOTS_DIR, f'csr_vs_dense_all_{user}.png')\n",
    "    fig.savefig(fname, dpi=300)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac48035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSR parallel speedup (baseline = sequential CSR) \n",
    "def plot_csr_parallel_speedup_subplots(df, user):\n",
    "    user_data = df[df['user'] == user].copy()\n",
    "    if user_data.empty:\n",
    "        return\n",
    "\n",
    "    # Get unique n values\n",
    "    n_values = sorted(user_data['n'].unique())\n",
    "    if len(n_values) == 0:\n",
    "        return\n",
    "\n",
    "    # Create subplots (2x2 grid)\n",
    "    nplots = min(len(n_values), 4)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, n in enumerate(n_values[:nplots]):\n",
    "        data = user_data[user_data['n'] == n].copy()\n",
    "        if data.empty:\n",
    "            continue\n",
    "\n",
    "        grouped = data.groupby(['sparsity','procs']).mean(numeric_only=True).reset_index()\n",
    "        ax = axes[idx]\n",
    "\n",
    "        sparsities = sorted(grouped['sparsity'].unique())\n",
    "        # Create offset for each sparsity level\n",
    "        offset_step = 0.15\n",
    "        offsets = np.linspace(-offset_step * (len(sparsities)-1)/2,\n",
    "                              offset_step * (len(sparsities)-1)/2,\n",
    "                              len(sparsities))\n",
    "\n",
    "        for sparsity_idx, (s, sdata) in enumerate(grouped.groupby('sparsity')):\n",
    "            sdata = sdata.sort_values('procs')\n",
    "            # Use raw data for baseline detection (sequential CSR Total = Construct + Send + SpMV)\n",
    "            raw_s = data[data['sparsity'] == s]\n",
    "            baseline_raw = raw_s[raw_s['procs_label'].str.lower() == 'sequential']\n",
    "            if not baseline_raw.empty:\n",
    "                b_construct = baseline_raw['time_csr_construct'].mean()\n",
    "                b_send = baseline_raw['time_send'].mean()\n",
    "                b_spmv = baseline_raw['time_spmv'].mean()\n",
    "                b = b_construct + b_send + b_spmv  # CSR Total\n",
    "                sb_construct = baseline_raw['time_csr_construct'].std() if baseline_raw['time_csr_construct'].std() else 0.0\n",
    "                sb_send = baseline_raw['time_send'].std() if baseline_raw['time_send'].std() else 0.0\n",
    "                sb_spmv = baseline_raw['time_spmv'].std() if baseline_raw['time_spmv'].std() else 0.0\n",
    "                sb = np.sqrt(sb_construct**2 + sb_send**2 + sb_spmv**2)  # Error propagation for sum\n",
    "            else:\n",
    "                raw_1 = raw_s[raw_s['procs'] == 1]\n",
    "                if raw_1.empty:\n",
    "                    continue\n",
    "                b_construct = raw_1['time_csr_construct'].mean()\n",
    "                b_send = raw_1['time_send'].mean()\n",
    "                b_spmv = raw_1['time_spmv'].mean()\n",
    "                b = b_construct + b_send + b_spmv\n",
    "                sb_construct = raw_1['time_csr_construct'].std() if not np.isnan(raw_1['time_csr_construct'].std()) else 0.0\n",
    "                sb_send = raw_1['time_send'].std() if not np.isnan(raw_1['time_send'].std()) else 0.0\n",
    "                sb_spmv = raw_1['time_spmv'].std() if not np.isnan(raw_1['time_spmv'].std()) else 0.0\n",
    "                sb = np.sqrt(sb_construct**2 + sb_send**2 + sb_spmv**2)\n",
    "\n",
    "            # Compute CSR Total means and stds for each process (excluding sequential)\n",
    "            raw_parallel = raw_s[raw_s['procs'] != -1]\n",
    "            csr_stats = raw_parallel.groupby('procs').agg({\n",
    "                'time_csr_construct': ['mean', 'std'],\n",
    "                'time_send': ['mean', 'std'],\n",
    "                'time_spmv': ['mean', 'std']\n",
    "            }).reset_index()\n",
    "            csr_stats.columns = ['procs', 'construct_mean', 'construct_std', 'send_mean', 'send_std', 'spmv_mean', 'spmv_std']\n",
    "            csr_stats['csr_total_mean'] = csr_stats['construct_mean'] + csr_stats['send_mean'] + csr_stats['spmv_mean']\n",
    "            csr_stats['csr_total_std'] = np.sqrt(csr_stats['construct_std'].fillna(0)**2 + \n",
    "                                                   csr_stats['send_std'].fillna(0)**2 +\n",
    "                                                   csr_stats['spmv_std'].fillna(0)**2)\n",
    "            csr_stats = csr_stats.sort_values('procs').reset_index(drop=True)\n",
    "\n",
    "            if csr_stats.empty:\n",
    "                continue\n",
    "\n",
    "            m = csr_stats['csr_total_mean'].values\n",
    "            sm = csr_stats['csr_total_std'].values\n",
    "            speedup_mean = b / m\n",
    "            # Propagate uncertainty: var = (sb^2)/(m^2) + (b^2)*(sm^2)/(m^4)\n",
    "            var = (sb**2) / (m**2) + (b**2) * (sm**2) / (m**4)\n",
    "            speedup_std = np.sqrt(var)\n",
    "            speedup_std = np.maximum(speedup_std, 0)\n",
    "\n",
    "            # Apply offset to x-axis positions\n",
    "            x_pos = csr_stats['procs'].values + offsets[sparsity_idx]\n",
    "            ax.errorbar(x_pos, speedup_mean, yerr=speedup_std,\n",
    "                       marker='o', label=f's={s}%', capsize=4)\n",
    "\n",
    "        # Add baseline reference at 1.0\n",
    "        ax.axhline(y=1.0, color='r', linestyle='--', alpha=0.5, label='No speedup (1.0x)')\n",
    "        \n",
    "        # Show process counts on the x-axis (excluding sequential)\n",
    "        all_procs = sorted([p for p in grouped['procs'].unique() if p != -1])\n",
    "        ax.set_xticks(all_procs)\n",
    "        ax.set_xticklabels([str(int(p)) for p in all_procs])\n",
    "        ax.set_xlabel('Processes')\n",
    "        ax.set_ylabel('Speedup (x)')\n",
    "        ax.set_title(f'n={n}')\n",
    "        ax.grid(True, alpha=0.25)\n",
    "        ax.legend(fontsize=8)\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for idx in range(nplots, 4):\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "    fig.suptitle(f'CSR Total Parallel Speedup vs Process Count (User: {user})', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fname = os.path.join(PLOTS_DIR, f'csr_parallel_speedup_all_{user}.png')\n",
    "    fig.savefig(fname, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# Dense vs CSR speedup (dense / csr) with same formatting\n",
    "def plot_dense_vs_csr_subplots(df, user):\n",
    "    user_data = df[df['user'] == user].copy()\n",
    "    if user_data.empty:\n",
    "        return\n",
    "\n",
    "    # Get unique n values\n",
    "    n_values = sorted(user_data['n'].unique())\n",
    "    if len(n_values) == 0:\n",
    "        return\n",
    "\n",
    "    # Create subplots (2x2 grid)\n",
    "    nplots = min(len(n_values), 4)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, n in enumerate(n_values[:nplots]):\n",
    "        data = user_data[user_data['n'] == n].copy()\n",
    "        if data.empty:\n",
    "            continue\n",
    "\n",
    "        grouped = data.groupby(['sparsity','procs']).mean(numeric_only=True).reset_index()\n",
    "        ax = axes[idx]\n",
    "\n",
    "        sparsities = sorted(grouped['sparsity'].unique())\n",
    "        # Create offset for each sparsity level\n",
    "        offset_step = 0.15\n",
    "        offsets = np.linspace(-offset_step * (len(sparsities)-1)/2,\n",
    "                              offset_step * (len(sparsities)-1)/2,\n",
    "                              len(sparsities))\n",
    "\n",
    "        for sparsity_idx, (s, sdata) in enumerate(grouped.groupby('sparsity')):\n",
    "            sdata = sdata.sort_values('procs')\n",
    "            \n",
    "            # Filter out sequential data - we compare parallel to parallel\n",
    "            sdata_parallel = sdata[sdata['procs'] != -1]\n",
    "            if sdata_parallel.empty:\n",
    "                continue\n",
    "            \n",
    "            # Use raw data to compute per-process means and stds\n",
    "            raw_s = data[data['sparsity'] == s]\n",
    "            raw_parallel = raw_s[raw_s['procs'] != -1]\n",
    "            \n",
    "            # Compute CSR Total (Construct + Send + SpMV) for each process\n",
    "            csr_stats = raw_parallel.groupby('procs').agg({\n",
    "                'time_csr_construct': ['mean', 'std'],\n",
    "                'time_send': ['mean', 'std'],\n",
    "                'time_spmv': ['mean', 'std']\n",
    "            }).reset_index()\n",
    "            \n",
    "            csr_stats.columns = ['procs', 'construct_mean', 'construct_std', 'send_mean', 'send_std', 'spmv_mean', 'spmv_std']\n",
    "            csr_stats['csr_total_mean'] = csr_stats['construct_mean'] + csr_stats['send_mean'] + csr_stats['spmv_mean']\n",
    "            csr_stats['csr_total_std'] = np.sqrt(csr_stats['construct_std'].fillna(0)**2 + \n",
    "                                                   csr_stats['send_std'].fillna(0)**2 +\n",
    "                                                   csr_stats['spmv_std'].fillna(0)**2)\n",
    "            \n",
    "            # Compute Dense stats for each process\n",
    "            dense_stats = raw_parallel.groupby('procs')['time_dense_total'].agg(['mean', 'std']).reset_index()\n",
    "            dense_stats.columns = ['procs', 'dense_mean', 'dense_std']\n",
    "            dense_stats['dense_std'] = dense_stats['dense_std'].fillna(0)\n",
    "            \n",
    "            # Merge CSR and Dense stats\n",
    "            merged = csr_stats.merge(dense_stats, on='procs')\n",
    "            if merged.empty:\n",
    "                continue\n",
    "            \n",
    "            # Calculate speedup: Dense / CSR (both parallel with same process count)\n",
    "            b = merged['csr_total_mean'].values\n",
    "            sb = merged['csr_total_std'].values\n",
    "            m = merged['dense_mean'].values\n",
    "            sm = merged['dense_std'].values\n",
    "            \n",
    "            speedup_mean = m / b\n",
    "            # Propagate uncertainty: var = (sm^2)/(b^2) + (m^2)*(sb^2)/(b^4)\n",
    "            var = (sm**2) / (b**2) + (m**2) * (sb**2) / (b**4)\n",
    "            speedup_std = np.sqrt(var)\n",
    "            speedup_std = np.maximum(speedup_std, 0)\n",
    "\n",
    "            x_pos = merged['procs'].values + offsets[sparsity_idx]\n",
    "            ax.errorbar(x_pos, speedup_mean, yerr=speedup_std,\n",
    "                       marker='o', label=f's={s}%', capsize=4)\n",
    "\n",
    "        # Add baseline reference at 1.0\n",
    "        ax.axhline(y=1.0, color='r', linestyle='--', alpha=0.5, label='Equal performance (1.0x)')\n",
    "        \n",
    "        # Show process counts on the x-axis (excluding sequential)\n",
    "        all_procs = sorted([p for p in grouped['procs'].unique() if p != -1])\n",
    "        ax.set_xticks(all_procs)\n",
    "        ax.set_xticklabels([str(int(p)) for p in all_procs])\n",
    "        ax.set_xlabel('Processes')\n",
    "        ax.set_ylabel('Speedup (Dense / CSR)')\n",
    "        ax.set_title(f'n={n}')\n",
    "        ax.grid(True, alpha=0.25)\n",
    "        ax.legend(fontsize=8)\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for idx in range(nplots, 4):\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "    fig.suptitle(f'Dense vs CSR Performance Ratio (User: {user})', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fname = os.path.join(PLOTS_DIR, f'dense_vs_csr_speedup_all_{user}.png')\n",
    "    fig.savefig(fname, dpi=300)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91370a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating plots for user: ea24205\n",
      "Generating plots for user: marr\n",
      "Generating plots for user: phoebus\n",
      "All plots generated and saved to /home/marr/threads/Thread-Experiments/3_2_sparse_array_vector_multiplication/plots\n"
     ]
    }
   ],
   "source": [
    "# Generate plots per user\n",
    "for user in sorted(res['user'].unique()):\n",
    "    user_df = res[res['user'] == user]\n",
    "    print(f'Generating plots for user: {user}')\n",
    "\n",
    "    plot_csr_vs_dense_subplots(res, user)\n",
    "    plot_csr_parallel_speedup_subplots(res, user)\n",
    "    plot_dense_vs_csr_subplots(res, user)\n",
    "\n",
    "print('All plots generated and saved to', PLOTS_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
