{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ea26eba",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "085106db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and CSV load\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "CSV_PATH = os.path.join(os.getcwd(), 'results_3.2.csv')\n",
    "PLOTS_DIR = os.path.join(os.getcwd(), 'plots')\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "\n",
    "# Read CSV and normalize types\n",
    "res = pd.read_csv(CSV_PATH)\n",
    "if 'user' not in res.columns:\n",
    "    res['user'] = 'unknown'\n",
    "\n",
    "res['n'] = res['n'].astype(int)\n",
    "res['sparsity'] = res['sparsity'].astype(int)\n",
    "res['reps'] = res['reps'].astype(int)\n",
    "# Preserve original threads label (so 'sequential' is not lost) and create a numeric threads column for plotting\n",
    "res['threads_label'] = res['procs'].astype(str)\n",
    "\n",
    "def threads_to_int(x):\n",
    "    if str(x).lower() == 'sequential':\n",
    "        return -1\n",
    "    try:\n",
    "        return int(x)\n",
    "    except Exception:\n",
    "        return 1\n",
    "\n",
    "res['threads'] = res['threads_label'].apply(threads_to_int)\n",
    "\n",
    "# Helper to create a filesystem-safe username\n",
    "def sanitize_user(u):\n",
    "    u = str(u)\n",
    "    u = u.strip()\n",
    "    u = re.sub(r\"[^0-9A-Za-z._-]\", '_', u)\n",
    "    return u\n",
    "\n",
    "# Component labels for timing breakdown (only components available in CSV)\n",
    "component_labels = {\n",
    "    'time_send': 'Send',\n",
    "    'time_csr_construct': 'CSR Construct',\n",
    "    'time_spmv': 'CSR SpMV',\n",
    "    'time_dense_total': 'Dense'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f38d91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timing breakdown multiplot (similar to plotter_2_1)\n",
    "def plot_timing_breakdown_multiplots(df, user):\n",
    "    user_data = df[df['user'] == user].copy()\n",
    "    if user_data.empty:\n",
    "        return\n",
    "    \n",
    "    # Get unique (n, sparsity) combinations\n",
    "    configs = user_data.groupby(['n', 'sparsity']).size().reset_index()[['n', 'sparsity']]\n",
    "    configs = configs.sort_values(['n', 'sparsity']).reset_index(drop=True)\n",
    "    \n",
    "    if len(configs) == 0:\n",
    "        return\n",
    "    \n",
    "    # Create subplots (2x2 grid)\n",
    "    nplots = min(len(configs), 4)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx in range(nplots):\n",
    "        n = configs.iloc[idx]['n']\n",
    "        sparsity = configs.iloc[idx]['sparsity']\n",
    "        \n",
    "        config_data = user_data[(user_data['n'] == n) & (user_data['sparsity'] == sparsity)].copy()\n",
    "        \n",
    "        # Compute mean and std across runs per threads\n",
    "        mean_data = config_data.groupby('threads').mean(numeric_only=True).reset_index()\n",
    "        std_data = config_data.groupby('threads').std(numeric_only=True).reset_index().fillna(0)\n",
    "        \n",
    "        mean_data = mean_data.sort_values('threads').reset_index(drop=True)\n",
    "        std_data = std_data.set_index('threads').reindex(mean_data['threads']).reset_index(drop=True)\n",
    "        \n",
    "        ax = axes[idx]\n",
    "        x_positions = np.arange(len(mean_data))\n",
    "        \n",
    "        bottom = np.zeros(len(mean_data))\n",
    "        available_components = [c for c in component_labels if c in mean_data.columns]\n",
    "        \n",
    "        for component in available_components:\n",
    "            values = mean_data[component].values\n",
    "            errs = std_data[component].values if component in std_data.columns else np.zeros_like(values)\n",
    "            # Clamp error bars to not go below zero\n",
    "            errs = np.minimum(errs, values)\n",
    "            ax.bar(x_positions, values, bottom=bottom, yerr=errs, capsize=3, \n",
    "                   label=component_labels[component], alpha=0.85, width=0.6)\n",
    "            bottom += values\n",
    "        \n",
    "        ax.set_xlabel('Number of Threads')\n",
    "        ax.set_ylabel('Time (seconds)')\n",
    "        ax.set_title(f'n={int(n)}, sparsity={int(sparsity)}%')\n",
    "        ax.set_xticks(x_positions)\n",
    "        tick_labels = mean_data['threads'].apply(lambda x: 'sequential' if int(x) == -1 else str(int(x)))\n",
    "        ax.set_xticklabels(tick_labels)\n",
    "        if idx == 0:\n",
    "            ax.legend(fontsize=8)\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(nplots, 4):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    fig.suptitle(f'Timing Breakdown per Configuration (User = {user})', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    uname = sanitize_user(user)\n",
    "    fname = os.path.join(PLOTS_DIR, f'timing_breakdown_all_configs_{uname}.png')\n",
    "    fig.savefig(fname, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "# Compact timing plots - now combined into subplots\n",
    "def plot_compact_timing_subplots(df, user):\n",
    "    user_data = df[df['user'] == user].copy()\n",
    "    if user_data.empty:\n",
    "        return\n",
    "    \n",
    "    # Get unique (n, sparsity) combinations\n",
    "    configs = user_data.groupby(['n', 'sparsity']).size().reset_index()[['n', 'sparsity']]\n",
    "    configs = configs.sort_values(['n', 'sparsity']).reset_index(drop=True)\n",
    "    \n",
    "    if len(configs) == 0:\n",
    "        return\n",
    "    \n",
    "    # Create subplots (2x2 grid)\n",
    "    nplots = min(len(configs), 4)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx in range(nplots):\n",
    "        n = configs.iloc[idx]['n']\n",
    "        sparsity = configs.iloc[idx]['sparsity']\n",
    "        \n",
    "        data = user_data[(user_data['n'] == n) & (user_data['sparsity'] == sparsity)].copy()\n",
    "        if data.empty:\n",
    "            continue\n",
    "            \n",
    "        summary_mean = data.groupby('threads').mean(numeric_only=True).reset_index()\n",
    "        summary_std = data.groupby('threads').std(numeric_only=True).reset_index().fillna(0)\n",
    "        summary_mean = summary_mean.sort_values('threads')\n",
    "        summary_std = summary_std.set_index('threads').reindex(summary_mean['threads']).reset_index(drop=True)\n",
    "\n",
    "        threads = summary_mean['threads'].values\n",
    "        width = 0.25\n",
    "        x = np.arange(len(threads))\n",
    "\n",
    "        ax = axes[idx]\n",
    "        # Clamp error bars for each component\n",
    "        err_csr = np.minimum(summary_std['time_csr_construct'].values, \n",
    "                             summary_mean['time_csr_construct'].values)\n",
    "        err_spmv = np.minimum(summary_std['time_spmv'].values, \n",
    "                              summary_mean['time_spmv'].values)\n",
    "        err_dense = np.minimum(summary_std['time_dense_total'].values, \n",
    "                               summary_mean['time_dense_total'].values)\n",
    "        \n",
    "        ax.bar(x - width, summary_mean['time_csr_construct'].values, width, \n",
    "               yerr=err_csr, capsize=3, \n",
    "               label='CSR construct', color='#4C72B0')\n",
    "        ax.bar(x, summary_mean['time_spmv'].values, width, \n",
    "               yerr=err_spmv, capsize=3, \n",
    "               label='CSR SpMV', color='#55A868')\n",
    "        ax.bar(x + width, summary_mean['time_dense_total'].values, width, \n",
    "               yerr=err_dense, capsize=3, \n",
    "               label='Dense', color='#C44E52')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels([str(int(t)) if t != -1 else 'seq' for t in threads])\n",
    "        ax.set_xlabel('Threads')\n",
    "        ax.set_ylabel('Time (s)')\n",
    "        ax.set_title(f'n={n} s={sparsity}%')\n",
    "        ax.grid(axis='y', alpha=0.25)\n",
    "        if idx == 0:\n",
    "            ax.legend(fontsize=8)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(nplots, 4):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    fig.suptitle(f'Compact Timing Comparison (User = {user})', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    uname = sanitize_user(user)\n",
    "    fname = os.path.join(PLOTS_DIR, f'compact_timing_all_{uname}.png')\n",
    "    fig.savefig(fname, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "# Speedup plots - now combined into subplots with offsets for distinguishability\n",
    "def plot_speedup_subplots(df, user):\n",
    "    user_data = df[df['user'] == user].copy()\n",
    "    if user_data.empty:\n",
    "        return\n",
    "    \n",
    "    # Get unique n values\n",
    "    n_values = sorted(user_data['n'].unique())\n",
    "    if len(n_values) == 0:\n",
    "        return\n",
    "    \n",
    "    # Create subplots (2x2 grid)\n",
    "    nplots = min(len(n_values), 4)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, n in enumerate(n_values[:nplots]):\n",
    "        data = user_data[user_data['n'] == n].copy()\n",
    "        if data.empty:\n",
    "            continue\n",
    "            \n",
    "        grouped = data.groupby(['sparsity','threads']).mean(numeric_only=True).reset_index()\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        sparsities = sorted(grouped['sparsity'].unique())\n",
    "        # Create offset for each sparsity level\n",
    "        offset_step = 0.15\n",
    "        offsets = np.linspace(-offset_step * (len(sparsities)-1)/2, \n",
    "                              offset_step * (len(sparsities)-1)/2, \n",
    "                              len(sparsities))\n",
    "        \n",
    "        for sparsity_idx, (s, sdata) in enumerate(grouped.groupby('sparsity')):\n",
    "            sdata = sdata.sort_values('threads')\n",
    "            # Use raw data for baseline detection\n",
    "            raw_s = data[data['sparsity'] == s]\n",
    "            baseline_raw = raw_s[raw_s['threads_label'].str.lower() == 'sequential']\n",
    "            if not baseline_raw.empty:\n",
    "                b = baseline_raw['time_spmv'].mean()\n",
    "                sb = baseline_raw['time_spmv'].std() if baseline_raw['time_spmv'].std() else 0.0\n",
    "            else:\n",
    "                b_series = raw_s[raw_s['threads'] == 1]['time_spmv']\n",
    "                if b_series.empty or b_series.mean() == 0:\n",
    "                    continue\n",
    "                b = b_series.mean()\n",
    "                sb = b_series.std() if not np.isnan(b_series.std()) else 0.0\n",
    "\n",
    "            # Compute means and stds\n",
    "            s_mean = sdata.groupby('threads')['time_spmv'].mean().reset_index()\n",
    "            s_std = sdata.groupby('threads')['time_spmv'].std().reset_index().fillna(0)\n",
    "            s_mean = s_mean.sort_values('threads').reset_index(drop=True)\n",
    "            s_std = s_std.set_index('threads').reindex(s_mean['threads']).reset_index(drop=True)\n",
    "\n",
    "            m = s_mean['time_spmv'].values\n",
    "            sm = s_std['time_spmv'].values\n",
    "            speedup_mean = b / m\n",
    "            # Propagate uncertainty\n",
    "            var = (sb**2) / (m**2) + (b**2) * (sm**2) / (m**4)\n",
    "            speedup_std = np.sqrt(var)\n",
    "            # Clamp error bars to not go below zero\n",
    "            speedup_std = np.minimum(speedup_std, speedup_mean)\n",
    "            \n",
    "            # Apply offset to x-axis positions\n",
    "            x_pos = s_mean['threads'].values + offsets[sparsity_idx]\n",
    "            ax.errorbar(x_pos, speedup_mean, yerr=speedup_std, \n",
    "                       marker='o', label=f's={s}%', capsize=4)\n",
    "\n",
    "        # Show thread counts on the x-axis\n",
    "        all_threads = sorted(grouped['threads'].unique())\n",
    "        ax.set_xticks(all_threads)\n",
    "        ax.set_xticklabels([str(int(t)) if t != -1 else 'seq' for t in all_threads])\n",
    "        ax.set_xlabel('Threads')\n",
    "        ax.set_ylabel('Speedup (x)')\n",
    "        ax.set_title(f'n={n}')\n",
    "        ax.grid(True, alpha=0.25)\n",
    "        ax.legend(fontsize=8)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(nplots, 4):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    fig.suptitle(f'Speedup (CSR SpMV) per Matrix Size (User = {user})', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    uname = sanitize_user(user)\n",
    "    fname = os.path.join(PLOTS_DIR, f'speedup_all_{uname}.png')\n",
    "    fig.savefig(fname, dpi=300)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91370a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating plots for user: marr\n",
      "Generating plots for user: phoebus\n",
      "All plots generated and saved to /home/marr/threads/Thread-Experiments/3_2_sparse_array_vector_multiplication/plots\n"
     ]
    }
   ],
   "source": [
    "# Generate plots per user\n",
    "for user in sorted(res['user'].unique()):\n",
    "    user_df = res[res['user'] == user]\n",
    "    uname = sanitize_user(user)\n",
    "    print(f'Generating plots for user: {user}')\n",
    "\n",
    "    # Generate timing breakdown multiplots\n",
    "    plot_timing_breakdown_multiplots(res, user)\n",
    "    \n",
    "    # Generate compact timing subplots (replaces individual plots)\n",
    "    plot_compact_timing_subplots(res, user)\n",
    "    \n",
    "    # Generate speedup subplots with offsets (replaces individual plots)\n",
    "    plot_speedup_subplots(res, user)\n",
    "\n",
    "# Summary plot: average relative improvement (dense - csr_spmv) / dense\n",
    "# Consolidated into subplots\n",
    "for user in sorted(res['user'].unique()):\n",
    "    user_df = res[res['user'] == user]\n",
    "    if user_df.empty: \n",
    "        continue\n",
    "    uname = sanitize_user(user)\n",
    "    \n",
    "    n_values = sorted(user_df['n'].unique())\n",
    "    if len(n_values) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Create subplots for improvement comparison\n",
    "    nplots = min(len(n_values), 4)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, n in enumerate(n_values[:nplots]):\n",
    "        svals = []\n",
    "        improvements_seq = []\n",
    "        improvements_par = []\n",
    "        \n",
    "        for s in sorted(user_df[user_df['n']==n]['sparsity'].unique()):\n",
    "            d = user_df[(user_df['n']==n) & (user_df['sparsity']==s)]\n",
    "            if d.empty: \n",
    "                continue\n",
    "            # sequential (threads==-1 or threads==1)\n",
    "            d1 = d[d['threads'].isin([-1, 1])]\n",
    "            if d1.empty: \n",
    "                continue\n",
    "            dense_seq = d1['time_dense_total'].mean()\n",
    "            csr_seq = d1['time_spmv'].mean()\n",
    "            if dense_seq > 0:\n",
    "                improvements_seq.append((dense_seq - csr_seq) / dense_seq)\n",
    "            # parallel: use max threads available in this subset\n",
    "            max_th = d['threads'].max()\n",
    "            dmax = d[d['threads']==max_th]\n",
    "            if not dmax.empty:\n",
    "                dense_par = dmax['time_dense_total'].mean()\n",
    "                csr_par = dmax['time_spmv'].mean()\n",
    "                if dense_par > 0:\n",
    "                    improvements_par.append((dense_par - csr_par) / dense_par)\n",
    "            svals.append(s)\n",
    "        \n",
    "        if not svals: \n",
    "            continue\n",
    "        avg_seq = np.mean(improvements_seq) if improvements_seq else 0.0\n",
    "        avg_par = np.mean(improvements_par) if improvements_par else 0.0\n",
    "\n",
    "        ax = axes[idx]\n",
    "        ax.bar([0,1], [avg_seq, avg_par], color=['#4C72B0','#55A868'], width=0.5)\n",
    "        ax.set_xticks([0,1])\n",
    "        ax.set_xticklabels(['sequential','parallel'])\n",
    "        ax.set_ylabel('Avg relative improvement')\n",
    "        ax.set_title(f'n={n}')\n",
    "        ax.set_ylim(bottom=0)\n",
    "        ax.grid(axis='y', alpha=0.25)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(nplots, 4):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    fig.suptitle(f'Avg CSR vs Dense Improvement (User = {user})', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    fname = os.path.join(PLOTS_DIR, f'avg_improv_all_{uname}.png')\n",
    "    fig.savefig(fname, dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "print('All plots generated and saved to', PLOTS_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
